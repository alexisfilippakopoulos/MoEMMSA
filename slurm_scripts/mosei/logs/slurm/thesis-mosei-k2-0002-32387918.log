Loading gcc/11.3.0
  Loading requirement: gmp/6.2.1 mpfr/4.1.0 mpc/1.2.1
$$$$$$$$$$$$$$$$$$$$$$$$$$$$$Running in normal mode.$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
Loading HF datasets
---------------------- Ongoing with TRAIN data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(16326, 500, 74)
(16326, 500, 35)
---------------------- Ongoing with VALID data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(1871, 500, 74)
(1871, 500, 35)
---------------------- Ongoing with TEST data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(4659, 500, 74)
(4659, 500, 35)
Ongoing with num_workers=2
ca list is: [7, 14, 21, 28, 35]
initializing SoftPerm
Ongoing with ----- sigmoid ----- gating
idx is 0
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 1
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 2
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 3
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 4
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Parsing decoder block: 0
Parsing decoder block: 1
Parsing decoder block: 2
Parsing decoder block: 3
Parsing decoder block: 4
Parsing decoder block: 5
Parsing decoder block: 6
Parsing decoder block: 7
COpying---------------------------------
Parsing decoder block: 8
Parsing decoder block: 9
Parsing decoder block: 10
Parsing decoder block: 11
Parsing decoder block: 12
Parsing decoder block: 13
Parsing decoder block: 14
COpying---------------------------------
Parsing decoder block: 15
Parsing decoder block: 16
Parsing decoder block: 17
Parsing decoder block: 18
Parsing decoder block: 19
Parsing decoder block: 20
Parsing decoder block: 21
COpying---------------------------------
Parsing decoder block: 22
Parsing decoder block: 23
Parsing decoder block: 24
Parsing decoder block: 25
Parsing decoder block: 26
Parsing decoder block: 27
Parsing decoder block: 28
COpying---------------------------------
Parsing decoder block: 29
Parsing decoder block: 30
Parsing decoder block: 31
Parsing decoder block: 32
Parsing decoder block: 33
Parsing decoder block: 34
Parsing decoder block: 35
COpying---------------------------------
No normalization is used
----------------->>> Pretrained AudioVisual Encoder <<<<<----------------
No normalization is used
----------------------- Loading AV encoder from /leonardo_work/EUHPC_A04_051/alexfil/DeepMLF-Reprod/checkpoints/bienc-mosei-1990/bienc-mosei-1990.pth
Copied param embed_positions_a._float_tensor
Copied param embed_positions_v._float_tensor
Copied param proj_a.weight
Copied param proj_v.weight
Copied param enc_a.layers.0.self_attn.in_proj_weight
Copied param enc_a.layers.0.self_attn.in_proj_bias
Copied param enc_a.layers.0.self_attn.out_proj.weight
Copied param enc_a.layers.0.self_attn.out_proj.bias
Copied param enc_a.layers.0.linear1.weight
Copied param enc_a.layers.0.linear1.bias
Copied param enc_a.layers.0.linear2.weight
Copied param enc_a.layers.0.linear2.bias
Copied param enc_a.layers.0.norm1.weight
Copied param enc_a.layers.0.norm1.bias
Copied param enc_a.layers.0.norm2.weight
Copied param enc_a.layers.0.norm2.bias
Copied param enc_a.layers.1.self_attn.in_proj_weight
Copied param enc_a.layers.1.self_attn.in_proj_bias
Copied param enc_a.layers.1.self_attn.out_proj.weight
Copied param enc_a.layers.1.self_attn.out_proj.bias
Copied param enc_a.layers.1.linear1.weight
Copied param enc_a.layers.1.linear1.bias
Copied param enc_a.layers.1.linear2.weight
Copied param enc_a.layers.1.linear2.bias
Copied param enc_a.layers.1.norm1.weight
Copied param enc_a.layers.1.norm1.bias
Copied param enc_a.layers.1.norm2.weight
Copied param enc_a.layers.1.norm2.bias
Copied param enc_a.layers.2.self_attn.in_proj_weight
Copied param enc_a.layers.2.self_attn.in_proj_bias
Copied param enc_a.layers.2.self_attn.out_proj.weight
Copied param enc_a.layers.2.self_attn.out_proj.bias
Copied param enc_a.layers.2.linear1.weight
Copied param enc_a.layers.2.linear1.bias
Copied param enc_a.layers.2.linear2.weight
Copied param enc_a.layers.2.linear2.bias
Copied param enc_a.layers.2.norm1.weight
Copied param enc_a.layers.2.norm1.bias
Copied param enc_a.layers.2.norm2.weight
Copied param enc_a.layers.2.norm2.bias
Copied param enc_v.layers.0.self_attn.in_proj_weight
Copied param enc_v.layers.0.self_attn.in_proj_bias
Copied param enc_v.layers.0.self_attn.out_proj.weight
Copied param enc_v.layers.0.self_attn.out_proj.bias
Copied param enc_v.layers.0.linear1.weight
Copied param enc_v.layers.0.linear1.bias
Copied param enc_v.layers.0.linear2.weight
Copied param enc_v.layers.0.linear2.bias
Copied param enc_v.layers.0.norm1.weight
Copied param enc_v.layers.0.norm1.bias
Copied param enc_v.layers.0.norm2.weight
Copied param enc_v.layers.0.norm2.bias
Copied param enc_v.layers.1.self_attn.in_proj_weight
Copied param enc_v.layers.1.self_attn.in_proj_bias
Copied param enc_v.layers.1.self_attn.out_proj.weight
Copied param enc_v.layers.1.self_attn.out_proj.bias
Copied param enc_v.layers.1.linear1.weight
Copied param enc_v.layers.1.linear1.bias
Copied param enc_v.layers.1.linear2.weight
Copied param enc_v.layers.1.linear2.bias
Copied param enc_v.layers.1.norm1.weight
Copied param enc_v.layers.1.norm1.bias
Copied param enc_v.layers.1.norm2.weight
Copied param enc_v.layers.1.norm2.bias
Copied param enc_v.layers.2.self_attn.in_proj_weight
Copied param enc_v.layers.2.self_attn.in_proj_bias
Copied param enc_v.layers.2.self_attn.out_proj.weight
Copied param enc_v.layers.2.self_attn.out_proj.bias
Copied param enc_v.layers.2.linear1.weight
Copied param enc_v.layers.2.linear1.bias
Copied param enc_v.layers.2.linear2.weight
Copied param enc_v.layers.2.linear2.bias
Copied param enc_v.layers.2.norm1.weight
Copied param enc_v.layers.2.norm1.bias
Copied param enc_v.layers.2.norm2.weight
Copied param enc_v.layers.2.norm2.bias
Copied param fusion.weight
Copied param fusion.bias
Copied param clf.weight
Copied param clf.bias
------------------ Adding LNorm ------------------------
ongoing with msalm
7.ca_layer.alpha_1
7.ca_layer.alpha_2
7.ca_layer.audio_expert.attn.W_q.weight
7.ca_layer.audio_expert.attn.W_kv.weight
7.ca_layer.audio_expert.attn.W_o.weight
7.ca_layer.audio_expert.attn.gate_linear.weight
7.ca_layer.visual_expert.attn.W_q.weight
7.ca_layer.visual_expert.attn.W_kv.weight
7.ca_layer.visual_expert.attn.W_o.weight
7.ca_layer.visual_expert.attn.gate_linear.weight
7.ca_layer.av_expert.attn.W_q.weight
7.ca_layer.av_expert.attn.W_kv.weight
7.ca_layer.av_expert.attn.W_o.weight
7.ca_layer.av_expert.attn.gate_linear.weight
7.ca_layer.ln_1.weight
7.ca_layer.ln_1.bias
7.ca_layer.ln_2.weight
7.ca_layer.ln_2.bias
7.ca_layer.mlp.c_fc.weight
7.ca_layer.mlp.c_fc.bias
7.ca_layer.mlp.c_proj.weight
7.ca_layer.mlp.c_proj.bias
14.ca_layer.alpha_1
14.ca_layer.alpha_2
14.ca_layer.audio_expert.attn.W_q.weight
14.ca_layer.audio_expert.attn.W_kv.weight
14.ca_layer.audio_expert.attn.W_o.weight
14.ca_layer.audio_expert.attn.gate_linear.weight
14.ca_layer.visual_expert.attn.W_q.weight
14.ca_layer.visual_expert.attn.W_kv.weight
14.ca_layer.visual_expert.attn.W_o.weight
14.ca_layer.visual_expert.attn.gate_linear.weight
14.ca_layer.av_expert.attn.W_q.weight
14.ca_layer.av_expert.attn.W_kv.weight
14.ca_layer.av_expert.attn.W_o.weight
14.ca_layer.av_expert.attn.gate_linear.weight
14.ca_layer.ln_1.weight
14.ca_layer.ln_1.bias
14.ca_layer.ln_2.weight
14.ca_layer.ln_2.bias
14.ca_layer.mlp.c_fc.weight
14.ca_layer.mlp.c_fc.bias
14.ca_layer.mlp.c_proj.weight
14.ca_layer.mlp.c_proj.bias
21.ca_layer.alpha_1
21.ca_layer.alpha_2
21.ca_layer.audio_expert.attn.W_q.weight
21.ca_layer.audio_expert.attn.W_kv.weight
21.ca_layer.audio_expert.attn.W_o.weight
21.ca_layer.audio_expert.attn.gate_linear.weight
21.ca_layer.visual_expert.attn.W_q.weight
21.ca_layer.visual_expert.attn.W_kv.weight
21.ca_layer.visual_expert.attn.W_o.weight
21.ca_layer.visual_expert.attn.gate_linear.weight
21.ca_layer.av_expert.attn.W_q.weight
21.ca_layer.av_expert.attn.W_kv.weight
21.ca_layer.av_expert.attn.W_o.weight
21.ca_layer.av_expert.attn.gate_linear.weight
21.ca_layer.ln_1.weight
21.ca_layer.ln_1.bias
21.ca_layer.ln_2.weight
21.ca_layer.ln_2.bias
21.ca_layer.mlp.c_fc.weight
21.ca_layer.mlp.c_fc.bias
21.ca_layer.mlp.c_proj.weight
21.ca_layer.mlp.c_proj.bias
28.ca_layer.alpha_1
28.ca_layer.alpha_2
28.ca_layer.audio_expert.attn.W_q.weight
28.ca_layer.audio_expert.attn.W_kv.weight
28.ca_layer.audio_expert.attn.W_o.weight
28.ca_layer.audio_expert.attn.gate_linear.weight
28.ca_layer.visual_expert.attn.W_q.weight
28.ca_layer.visual_expert.attn.W_kv.weight
28.ca_layer.visual_expert.attn.W_o.weight
28.ca_layer.visual_expert.attn.gate_linear.weight
28.ca_layer.av_expert.attn.W_q.weight
28.ca_layer.av_expert.attn.W_kv.weight
28.ca_layer.av_expert.attn.W_o.weight
28.ca_layer.av_expert.attn.gate_linear.weight
28.ca_layer.ln_1.weight
28.ca_layer.ln_1.bias
28.ca_layer.ln_2.weight
28.ca_layer.ln_2.bias
28.ca_layer.mlp.c_fc.weight
28.ca_layer.mlp.c_fc.bias
28.ca_layer.mlp.c_proj.weight
28.ca_layer.mlp.c_proj.bias
35.ca_layer.alpha_1
35.ca_layer.alpha_2
35.ca_layer.audio_expert.attn.W_q.weight
35.ca_layer.audio_expert.attn.W_kv.weight
35.ca_layer.audio_expert.attn.W_o.weight
35.ca_layer.audio_expert.attn.gate_linear.weight
35.ca_layer.visual_expert.attn.W_q.weight
35.ca_layer.visual_expert.attn.W_kv.weight
35.ca_layer.visual_expert.attn.W_o.weight
35.ca_layer.visual_expert.attn.gate_linear.weight
35.ca_layer.av_expert.attn.W_q.weight
35.ca_layer.av_expert.attn.W_kv.weight
35.ca_layer.av_expert.attn.W_o.weight
35.ca_layer.av_expert.attn.gate_linear.weight
35.ca_layer.ln_1.weight
35.ca_layer.ln_1.bias
35.ca_layer.ln_2.weight
35.ca_layer.ln_2.bias
35.ca_layer.mlp.c_fc.weight
35.ca_layer.mlp.c_fc.bias
35.ca_layer.mlp.c_proj.weight
35.ca_layer.mlp.c_proj.bias
0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.W_task.0.weight
Model.W_task.0.bias
Model.W_task.1.weight
Model.W_task.1.bias
Model.W_task.3.weight
Model.W_task.3.bias
Model.W_bn.weight
Model.W_bn.bias
Model.W_text.weight
Model.W_text.bias
Model.W_av.weight
Model.W_av.bias
Model.av_encoder.proj_a.weight
Model.av_encoder.proj_v.weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.0.linear1.weight
Model.av_encoder.enc_a.layers.0.linear1.bias
Model.av_encoder.enc_a.layers.0.linear2.weight
Model.av_encoder.enc_a.layers.0.linear2.bias
Model.av_encoder.enc_a.layers.0.norm1.weight
Model.av_encoder.enc_a.layers.0.norm1.bias
Model.av_encoder.enc_a.layers.0.norm2.weight
Model.av_encoder.enc_a.layers.0.norm2.bias
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.1.linear1.weight
Model.av_encoder.enc_a.layers.1.linear1.bias
Model.av_encoder.enc_a.layers.1.linear2.weight
Model.av_encoder.enc_a.layers.1.linear2.bias
Model.av_encoder.enc_a.layers.1.norm1.weight
Model.av_encoder.enc_a.layers.1.norm1.bias
Model.av_encoder.enc_a.layers.1.norm2.weight
Model.av_encoder.enc_a.layers.1.norm2.bias
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.2.linear1.weight
Model.av_encoder.enc_a.layers.2.linear1.bias
Model.av_encoder.enc_a.layers.2.linear2.weight
Model.av_encoder.enc_a.layers.2.linear2.bias
Model.av_encoder.enc_a.layers.2.norm1.weight
Model.av_encoder.enc_a.layers.2.norm1.bias
Model.av_encoder.enc_a.layers.2.norm2.weight
Model.av_encoder.enc_a.layers.2.norm2.bias
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.0.linear1.weight
Model.av_encoder.enc_v.layers.0.linear1.bias
Model.av_encoder.enc_v.layers.0.linear2.weight
Model.av_encoder.enc_v.layers.0.linear2.bias
Model.av_encoder.enc_v.layers.0.norm1.weight
Model.av_encoder.enc_v.layers.0.norm1.bias
Model.av_encoder.enc_v.layers.0.norm2.weight
Model.av_encoder.enc_v.layers.0.norm2.bias
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.1.linear1.weight
Model.av_encoder.enc_v.layers.1.linear1.bias
Model.av_encoder.enc_v.layers.1.linear2.weight
Model.av_encoder.enc_v.layers.1.linear2.bias
Model.av_encoder.enc_v.layers.1.norm1.weight
Model.av_encoder.enc_v.layers.1.norm1.bias
Model.av_encoder.enc_v.layers.1.norm2.weight
Model.av_encoder.enc_v.layers.1.norm2.bias
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.2.linear1.weight
Model.av_encoder.enc_v.layers.2.linear1.bias
Model.av_encoder.enc_v.layers.2.linear2.weight
Model.av_encoder.enc_v.layers.2.linear2.bias
Model.av_encoder.enc_v.layers.2.norm1.weight
Model.av_encoder.enc_v.layers.2.norm1.bias
Model.av_encoder.enc_v.layers.2.norm2.weight
Model.av_encoder.enc_v.layers.2.norm2.bias
Model.av_encoder.fusion.weight
Model.av_encoder.fusion.bias
Model.av_encoder.clf.weight
Model.av_encoder.clf.bias
Model.LN.weight
Model.LN.bias
The total number of trainable parameters is 140.73 M
Model.lang_encoder.transformer.wte.0.embedding.weight
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Using grad with decay in Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wpe.0.positional.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.ln_f.weight
Model.lang_encoder.transformer.ln_f.bias
Model.W_task.0.weight
Using grad with decay in Model.W_task.0.weight
Model.W_task.0.bias
Using grad with no decay in Model.W_task.0.bias
Model.W_task.1.weight
Using grad with decay in Model.W_task.1.weight
Model.W_task.1.bias
Using grad with no decay in Model.W_task.1.bias
Model.W_task.3.weight
Using grad with decay in Model.W_task.3.weight
Model.W_task.3.bias
Using grad with no decay in Model.W_task.3.bias
Model.W_bn.weight
Using grad with decay in Model.W_bn.weight
Model.W_bn.bias
Using grad with no decay in Model.W_bn.bias
Model.W_text.weight
Using grad with decay in Model.W_text.weight
Model.W_text.bias
Using grad with no decay in Model.W_text.bias
Model.W_av.weight
Using grad with decay in Model.W_av.weight
Model.W_av.bias
Using grad with no decay in Model.W_av.bias
Model.LN.weight
Using grad with decay in Model.LN.weight
Model.LN.bias
Using grad with no decay in Model.LN.bias
Will be using warmup for 63 steps
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0018], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0036], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0019], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0018], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0014], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0004], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0015], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0007], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0009], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0007], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0048], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0123], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0100], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0032], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0042], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0054], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0023], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0019], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0013], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0094], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0058], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0207], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0139], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0017], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0054], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0101], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0029], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0058], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0015], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0177], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0076], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0274], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0160], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0037], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0056], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0166], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0039], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0110], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0022], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0263], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0097], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0321], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0179], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0107], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0048], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0231], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0050], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0167], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0028], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0342], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0129], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0330], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0191], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0190], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0057], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0309], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0066], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0236], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0039], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0433], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0173], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0329], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0215], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0277], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0070], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0386], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0088], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0301], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0051], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0516], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0208], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0312], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0217], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0351], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0077], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0457], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0108], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0365], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0065], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0597], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0251], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0279], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0228], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0417], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0088], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0507], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0121], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0410], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0076], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0664], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0288], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0262], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0240], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0481], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0102], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0565], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0147], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0466], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0089], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0733], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0320], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0237], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0251], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0537], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0117], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0618], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0172], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0518], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0099], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0796], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0344], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0215], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0257], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0583], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0130], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0663], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0196], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0562], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0108], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0849], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0371], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0193], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0268], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0623], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0141], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0701], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0214], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0600], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0118], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0895], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0394], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0179], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0276], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0658], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0158], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0733], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0233], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0631], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0126], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0931], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0410], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0161], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0284], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0683], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0168], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0759], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0246], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0657], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0133], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0960], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0422], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0151], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0287], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0702], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0177], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0777], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0258], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0675], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0139], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0981], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0430], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0143], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0291], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0715], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0184], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0790], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0267], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0688], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0144], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0996], device='cuda:0', requires_grad=True)
***************** Loading Model from checkpoints/thesis-mosei/msalm-mosei-1990.pth
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0173], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0329], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0215], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0277], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0070], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0386], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0088], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0301], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0051], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0516], device='cuda:0', requires_grad=True)
Deleting stored model from checkpoints/thesis-mosei/msalm-mosei-1990.pth
Loading HF datasets
---------------------- Ongoing with TRAIN data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(16326, 500, 74)
(16326, 500, 35)
---------------------- Ongoing with VALID data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(1871, 500, 74)
(1871, 500, 35)
---------------------- Ongoing with TEST data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(4659, 500, 74)
(4659, 500, 35)
Ongoing with num_workers=2
ca list is: [7, 14, 21, 28, 35]
initializing SoftPerm
Ongoing with ----- sigmoid ----- gating
idx is 0
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 1
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 2
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 3
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 4
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Parsing decoder block: 0
Parsing decoder block: 1
Parsing decoder block: 2
Parsing decoder block: 3
Parsing decoder block: 4
Parsing decoder block: 5
Parsing decoder block: 6
Parsing decoder block: 7
COpying---------------------------------
Parsing decoder block: 8
Parsing decoder block: 9
Parsing decoder block: 10
Parsing decoder block: 11
Parsing decoder block: 12
Parsing decoder block: 13
Parsing decoder block: 14
COpying---------------------------------
Parsing decoder block: 15
Parsing decoder block: 16
Parsing decoder block: 17
Parsing decoder block: 18
Parsing decoder block: 19
Parsing decoder block: 20
Parsing decoder block: 21
COpying---------------------------------
Parsing decoder block: 22
Parsing decoder block: 23
Parsing decoder block: 24
Parsing decoder block: 25
Parsing decoder block: 26
Parsing decoder block: 27
Parsing decoder block: 28
COpying---------------------------------
Parsing decoder block: 29
Parsing decoder block: 30
Parsing decoder block: 31
Parsing decoder block: 32
Parsing decoder block: 33
Parsing decoder block: 34
Parsing decoder block: 35
COpying---------------------------------
No normalization is used
----------------->>> Pretrained AudioVisual Encoder <<<<<----------------
No normalization is used
----------------------- Loading AV encoder from /leonardo_work/EUHPC_A04_051/alexfil/DeepMLF-Reprod/checkpoints/bienc-mosei-1990/bienc-mosei-1990.pth
Copied param embed_positions_a._float_tensor
Copied param embed_positions_v._float_tensor
Copied param proj_a.weight
Copied param proj_v.weight
Copied param enc_a.layers.0.self_attn.in_proj_weight
Copied param enc_a.layers.0.self_attn.in_proj_bias
Copied param enc_a.layers.0.self_attn.out_proj.weight
Copied param enc_a.layers.0.self_attn.out_proj.bias
Copied param enc_a.layers.0.linear1.weight
Copied param enc_a.layers.0.linear1.bias
Copied param enc_a.layers.0.linear2.weight
Copied param enc_a.layers.0.linear2.bias
Copied param enc_a.layers.0.norm1.weight
Copied param enc_a.layers.0.norm1.bias
Copied param enc_a.layers.0.norm2.weight
Copied param enc_a.layers.0.norm2.bias
Copied param enc_a.layers.1.self_attn.in_proj_weight
Copied param enc_a.layers.1.self_attn.in_proj_bias
Copied param enc_a.layers.1.self_attn.out_proj.weight
Copied param enc_a.layers.1.self_attn.out_proj.bias
Copied param enc_a.layers.1.linear1.weight
Copied param enc_a.layers.1.linear1.bias
Copied param enc_a.layers.1.linear2.weight
Copied param enc_a.layers.1.linear2.bias
Copied param enc_a.layers.1.norm1.weight
Copied param enc_a.layers.1.norm1.bias
Copied param enc_a.layers.1.norm2.weight
Copied param enc_a.layers.1.norm2.bias
Copied param enc_a.layers.2.self_attn.in_proj_weight
Copied param enc_a.layers.2.self_attn.in_proj_bias
Copied param enc_a.layers.2.self_attn.out_proj.weight
Copied param enc_a.layers.2.self_attn.out_proj.bias
Copied param enc_a.layers.2.linear1.weight
Copied param enc_a.layers.2.linear1.bias
Copied param enc_a.layers.2.linear2.weight
Copied param enc_a.layers.2.linear2.bias
Copied param enc_a.layers.2.norm1.weight
Copied param enc_a.layers.2.norm1.bias
Copied param enc_a.layers.2.norm2.weight
Copied param enc_a.layers.2.norm2.bias
Copied param enc_v.layers.0.self_attn.in_proj_weight
Copied param enc_v.layers.0.self_attn.in_proj_bias
Copied param enc_v.layers.0.self_attn.out_proj.weight
Copied param enc_v.layers.0.self_attn.out_proj.bias
Copied param enc_v.layers.0.linear1.weight
Copied param enc_v.layers.0.linear1.bias
Copied param enc_v.layers.0.linear2.weight
Copied param enc_v.layers.0.linear2.bias
Copied param enc_v.layers.0.norm1.weight
Copied param enc_v.layers.0.norm1.bias
Copied param enc_v.layers.0.norm2.weight
Copied param enc_v.layers.0.norm2.bias
Copied param enc_v.layers.1.self_attn.in_proj_weight
Copied param enc_v.layers.1.self_attn.in_proj_bias
Copied param enc_v.layers.1.self_attn.out_proj.weight
Copied param enc_v.layers.1.self_attn.out_proj.bias
Copied param enc_v.layers.1.linear1.weight
Copied param enc_v.layers.1.linear1.bias
Copied param enc_v.layers.1.linear2.weight
Copied param enc_v.layers.1.linear2.bias
Copied param enc_v.layers.1.norm1.weight
Copied param enc_v.layers.1.norm1.bias
Copied param enc_v.layers.1.norm2.weight
Copied param enc_v.layers.1.norm2.bias
Copied param enc_v.layers.2.self_attn.in_proj_weight
Copied param enc_v.layers.2.self_attn.in_proj_bias
Copied param enc_v.layers.2.self_attn.out_proj.weight
Copied param enc_v.layers.2.self_attn.out_proj.bias
Copied param enc_v.layers.2.linear1.weight
Copied param enc_v.layers.2.linear1.bias
Copied param enc_v.layers.2.linear2.weight
Copied param enc_v.layers.2.linear2.bias
Copied param enc_v.layers.2.norm1.weight
Copied param enc_v.layers.2.norm1.bias
Copied param enc_v.layers.2.norm2.weight
Copied param enc_v.layers.2.norm2.bias
Copied param fusion.weight
Copied param fusion.bias
Copied param clf.weight
Copied param clf.bias
------------------ Adding LNorm ------------------------
ongoing with msalm
7.ca_layer.alpha_1
7.ca_layer.alpha_2
7.ca_layer.audio_expert.attn.W_q.weight
7.ca_layer.audio_expert.attn.W_kv.weight
7.ca_layer.audio_expert.attn.W_o.weight
7.ca_layer.audio_expert.attn.gate_linear.weight
7.ca_layer.visual_expert.attn.W_q.weight
7.ca_layer.visual_expert.attn.W_kv.weight
7.ca_layer.visual_expert.attn.W_o.weight
7.ca_layer.visual_expert.attn.gate_linear.weight
7.ca_layer.av_expert.attn.W_q.weight
7.ca_layer.av_expert.attn.W_kv.weight
7.ca_layer.av_expert.attn.W_o.weight
7.ca_layer.av_expert.attn.gate_linear.weight
7.ca_layer.ln_1.weight
7.ca_layer.ln_1.bias
7.ca_layer.ln_2.weight
7.ca_layer.ln_2.bias
7.ca_layer.mlp.c_fc.weight
7.ca_layer.mlp.c_fc.bias
7.ca_layer.mlp.c_proj.weight
7.ca_layer.mlp.c_proj.bias
14.ca_layer.alpha_1
14.ca_layer.alpha_2
14.ca_layer.audio_expert.attn.W_q.weight
14.ca_layer.audio_expert.attn.W_kv.weight
14.ca_layer.audio_expert.attn.W_o.weight
14.ca_layer.audio_expert.attn.gate_linear.weight
14.ca_layer.visual_expert.attn.W_q.weight
14.ca_layer.visual_expert.attn.W_kv.weight
14.ca_layer.visual_expert.attn.W_o.weight
14.ca_layer.visual_expert.attn.gate_linear.weight
14.ca_layer.av_expert.attn.W_q.weight
14.ca_layer.av_expert.attn.W_kv.weight
14.ca_layer.av_expert.attn.W_o.weight
14.ca_layer.av_expert.attn.gate_linear.weight
14.ca_layer.ln_1.weight
14.ca_layer.ln_1.bias
14.ca_layer.ln_2.weight
14.ca_layer.ln_2.bias
14.ca_layer.mlp.c_fc.weight
14.ca_layer.mlp.c_fc.bias
14.ca_layer.mlp.c_proj.weight
14.ca_layer.mlp.c_proj.bias
21.ca_layer.alpha_1
21.ca_layer.alpha_2
21.ca_layer.audio_expert.attn.W_q.weight
21.ca_layer.audio_expert.attn.W_kv.weight
21.ca_layer.audio_expert.attn.W_o.weight
21.ca_layer.audio_expert.attn.gate_linear.weight
21.ca_layer.visual_expert.attn.W_q.weight
21.ca_layer.visual_expert.attn.W_kv.weight
21.ca_layer.visual_expert.attn.W_o.weight
21.ca_layer.visual_expert.attn.gate_linear.weight
21.ca_layer.av_expert.attn.W_q.weight
21.ca_layer.av_expert.attn.W_kv.weight
21.ca_layer.av_expert.attn.W_o.weight
21.ca_layer.av_expert.attn.gate_linear.weight
21.ca_layer.ln_1.weight
21.ca_layer.ln_1.bias
21.ca_layer.ln_2.weight
21.ca_layer.ln_2.bias
21.ca_layer.mlp.c_fc.weight
21.ca_layer.mlp.c_fc.bias
21.ca_layer.mlp.c_proj.weight
21.ca_layer.mlp.c_proj.bias
28.ca_layer.alpha_1
28.ca_layer.alpha_2
28.ca_layer.audio_expert.attn.W_q.weight
28.ca_layer.audio_expert.attn.W_kv.weight
28.ca_layer.audio_expert.attn.W_o.weight
28.ca_layer.audio_expert.attn.gate_linear.weight
28.ca_layer.visual_expert.attn.W_q.weight
28.ca_layer.visual_expert.attn.W_kv.weight
28.ca_layer.visual_expert.attn.W_o.weight
28.ca_layer.visual_expert.attn.gate_linear.weight
28.ca_layer.av_expert.attn.W_q.weight
28.ca_layer.av_expert.attn.W_kv.weight
28.ca_layer.av_expert.attn.W_o.weight
28.ca_layer.av_expert.attn.gate_linear.weight
28.ca_layer.ln_1.weight
28.ca_layer.ln_1.bias
28.ca_layer.ln_2.weight
28.ca_layer.ln_2.bias
28.ca_layer.mlp.c_fc.weight
28.ca_layer.mlp.c_fc.bias
28.ca_layer.mlp.c_proj.weight
28.ca_layer.mlp.c_proj.bias
35.ca_layer.alpha_1
35.ca_layer.alpha_2
35.ca_layer.audio_expert.attn.W_q.weight
35.ca_layer.audio_expert.attn.W_kv.weight
35.ca_layer.audio_expert.attn.W_o.weight
35.ca_layer.audio_expert.attn.gate_linear.weight
35.ca_layer.visual_expert.attn.W_q.weight
35.ca_layer.visual_expert.attn.W_kv.weight
35.ca_layer.visual_expert.attn.W_o.weight
35.ca_layer.visual_expert.attn.gate_linear.weight
35.ca_layer.av_expert.attn.W_q.weight
35.ca_layer.av_expert.attn.W_kv.weight
35.ca_layer.av_expert.attn.W_o.weight
35.ca_layer.av_expert.attn.gate_linear.weight
35.ca_layer.ln_1.weight
35.ca_layer.ln_1.bias
35.ca_layer.ln_2.weight
35.ca_layer.ln_2.bias
35.ca_layer.mlp.c_fc.weight
35.ca_layer.mlp.c_fc.bias
35.ca_layer.mlp.c_proj.weight
35.ca_layer.mlp.c_proj.bias
0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.W_task.0.weight
Model.W_task.0.bias
Model.W_task.1.weight
Model.W_task.1.bias
Model.W_task.3.weight
Model.W_task.3.bias
Model.W_bn.weight
Model.W_bn.bias
Model.W_text.weight
Model.W_text.bias
Model.W_av.weight
Model.W_av.bias
Model.av_encoder.proj_a.weight
Model.av_encoder.proj_v.weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.0.linear1.weight
Model.av_encoder.enc_a.layers.0.linear1.bias
Model.av_encoder.enc_a.layers.0.linear2.weight
Model.av_encoder.enc_a.layers.0.linear2.bias
Model.av_encoder.enc_a.layers.0.norm1.weight
Model.av_encoder.enc_a.layers.0.norm1.bias
Model.av_encoder.enc_a.layers.0.norm2.weight
Model.av_encoder.enc_a.layers.0.norm2.bias
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.1.linear1.weight
Model.av_encoder.enc_a.layers.1.linear1.bias
Model.av_encoder.enc_a.layers.1.linear2.weight
Model.av_encoder.enc_a.layers.1.linear2.bias
Model.av_encoder.enc_a.layers.1.norm1.weight
Model.av_encoder.enc_a.layers.1.norm1.bias
Model.av_encoder.enc_a.layers.1.norm2.weight
Model.av_encoder.enc_a.layers.1.norm2.bias
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.2.linear1.weight
Model.av_encoder.enc_a.layers.2.linear1.bias
Model.av_encoder.enc_a.layers.2.linear2.weight
Model.av_encoder.enc_a.layers.2.linear2.bias
Model.av_encoder.enc_a.layers.2.norm1.weight
Model.av_encoder.enc_a.layers.2.norm1.bias
Model.av_encoder.enc_a.layers.2.norm2.weight
Model.av_encoder.enc_a.layers.2.norm2.bias
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.0.linear1.weight
Model.av_encoder.enc_v.layers.0.linear1.bias
Model.av_encoder.enc_v.layers.0.linear2.weight
Model.av_encoder.enc_v.layers.0.linear2.bias
Model.av_encoder.enc_v.layers.0.norm1.weight
Model.av_encoder.enc_v.layers.0.norm1.bias
Model.av_encoder.enc_v.layers.0.norm2.weight
Model.av_encoder.enc_v.layers.0.norm2.bias
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.1.linear1.weight
Model.av_encoder.enc_v.layers.1.linear1.bias
Model.av_encoder.enc_v.layers.1.linear2.weight
Model.av_encoder.enc_v.layers.1.linear2.bias
Model.av_encoder.enc_v.layers.1.norm1.weight
Model.av_encoder.enc_v.layers.1.norm1.bias
Model.av_encoder.enc_v.layers.1.norm2.weight
Model.av_encoder.enc_v.layers.1.norm2.bias
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.2.linear1.weight
Model.av_encoder.enc_v.layers.2.linear1.bias
Model.av_encoder.enc_v.layers.2.linear2.weight
Model.av_encoder.enc_v.layers.2.linear2.bias
Model.av_encoder.enc_v.layers.2.norm1.weight
Model.av_encoder.enc_v.layers.2.norm1.bias
Model.av_encoder.enc_v.layers.2.norm2.weight
Model.av_encoder.enc_v.layers.2.norm2.bias
Model.av_encoder.fusion.weight
Model.av_encoder.fusion.bias
Model.av_encoder.clf.weight
Model.av_encoder.clf.bias
Model.LN.weight
Model.LN.bias
The total number of trainable parameters is 140.73 M
Model.lang_encoder.transformer.wte.0.embedding.weight
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Using grad with decay in Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wpe.0.positional.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.ln_f.weight
Model.lang_encoder.transformer.ln_f.bias
Model.W_task.0.weight
Using grad with decay in Model.W_task.0.weight
Model.W_task.0.bias
Using grad with no decay in Model.W_task.0.bias
Model.W_task.1.weight
Using grad with decay in Model.W_task.1.weight
Model.W_task.1.bias
Using grad with no decay in Model.W_task.1.bias
Model.W_task.3.weight
Using grad with decay in Model.W_task.3.weight
Model.W_task.3.bias
Using grad with no decay in Model.W_task.3.bias
Model.W_bn.weight
Using grad with decay in Model.W_bn.weight
Model.W_bn.bias
Using grad with no decay in Model.W_bn.bias
Model.W_text.weight
Using grad with decay in Model.W_text.weight
Model.W_text.bias
Using grad with no decay in Model.W_text.bias
Model.W_av.weight
Using grad with decay in Model.W_av.weight
Model.W_av.bias
Using grad with no decay in Model.W_av.bias
Model.LN.weight
Using grad with decay in Model.LN.weight
Model.LN.bias
Using grad with no decay in Model.LN.bias
Will be using warmup for 63 steps
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0013], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0044], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0028], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0019], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0020], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0003], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0009], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0006], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0010], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0008], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0070], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0133], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0097], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0046], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0051], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0033], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0009], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([3.3237e-05], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0009], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0087], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0085], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0224], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0129], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0038], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0065], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0077], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0021], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0042], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0022], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0167], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0110], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0286], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0153], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0014], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0070], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0130], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0024], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0083], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0022], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0236], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0144], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0315], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0175], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0086], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0076], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0185], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0031], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0130], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0033], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0308], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0186], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0315], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0198], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0172], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0083], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0250], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0047], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0191], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0046], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0385], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0225], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0298], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0212], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0250], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0091], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0316], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0059], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0253], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0061], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0458], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0267], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0283], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0237], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0320], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0105], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0374], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0080], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0306], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0075], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0528], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0309], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0264], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0255], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0388], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0114], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0428], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0099], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0355], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0087], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0596], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0356], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0231], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0269], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0453], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0137], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0483], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0132], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0408], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0104], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0661], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0385], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0203], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0287], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0508], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0153], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0533], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0156], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0457], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0116], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0718], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0411], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0185], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0297], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0556], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0168], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0574], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0179], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0502], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0129], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0771], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0437], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0164], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0306], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0595], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0181], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0610], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0200], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0539], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0142], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0815], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0458], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0146], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0315], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0627], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0192], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0639], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0218], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0570], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0154], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0851], device='cuda:0', requires_grad=True)
***************** Loading Model from checkpoints/thesis-mosei/msalm-mosei-1991.pth
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0110], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0286], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0153], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0014], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0070], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0130], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0024], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0083], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0022], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0236], device='cuda:0', requires_grad=True)
Deleting stored model from checkpoints/thesis-mosei/msalm-mosei-1991.pth
Loading HF datasets
---------------------- Ongoing with TRAIN data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(16326, 500, 74)
(16326, 500, 35)
---------------------- Ongoing with VALID data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(1871, 500, 74)
(1871, 500, 35)
---------------------- Ongoing with TEST data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(4659, 500, 74)
(4659, 500, 35)
Ongoing with num_workers=2
ca list is: [7, 14, 21, 28, 35]
initializing SoftPerm
Ongoing with ----- sigmoid ----- gating
idx is 0
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 1
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 2
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 3
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 4
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Parsing decoder block: 0
Parsing decoder block: 1
Parsing decoder block: 2
Parsing decoder block: 3
Parsing decoder block: 4
Parsing decoder block: 5
Parsing decoder block: 6
Parsing decoder block: 7
COpying---------------------------------
Parsing decoder block: 8
Parsing decoder block: 9
Parsing decoder block: 10
Parsing decoder block: 11
Parsing decoder block: 12
Parsing decoder block: 13
Parsing decoder block: 14
COpying---------------------------------
Parsing decoder block: 15
Parsing decoder block: 16
Parsing decoder block: 17
Parsing decoder block: 18
Parsing decoder block: 19
Parsing decoder block: 20
Parsing decoder block: 21
COpying---------------------------------
Parsing decoder block: 22
Parsing decoder block: 23
Parsing decoder block: 24
Parsing decoder block: 25
Parsing decoder block: 26
Parsing decoder block: 27
Parsing decoder block: 28
COpying---------------------------------
Parsing decoder block: 29
Parsing decoder block: 30
Parsing decoder block: 31
Parsing decoder block: 32
Parsing decoder block: 33
Parsing decoder block: 34
Parsing decoder block: 35
COpying---------------------------------
No normalization is used
----------------->>> Pretrained AudioVisual Encoder <<<<<----------------
No normalization is used
----------------------- Loading AV encoder from /leonardo_work/EUHPC_A04_051/alexfil/DeepMLF-Reprod/checkpoints/bienc-mosei-1990/bienc-mosei-1990.pth
Copied param embed_positions_a._float_tensor
Copied param embed_positions_v._float_tensor
Copied param proj_a.weight
Copied param proj_v.weight
Copied param enc_a.layers.0.self_attn.in_proj_weight
Copied param enc_a.layers.0.self_attn.in_proj_bias
Copied param enc_a.layers.0.self_attn.out_proj.weight
Copied param enc_a.layers.0.self_attn.out_proj.bias
Copied param enc_a.layers.0.linear1.weight
Copied param enc_a.layers.0.linear1.bias
Copied param enc_a.layers.0.linear2.weight
Copied param enc_a.layers.0.linear2.bias
Copied param enc_a.layers.0.norm1.weight
Copied param enc_a.layers.0.norm1.bias
Copied param enc_a.layers.0.norm2.weight
Copied param enc_a.layers.0.norm2.bias
Copied param enc_a.layers.1.self_attn.in_proj_weight
Copied param enc_a.layers.1.self_attn.in_proj_bias
Copied param enc_a.layers.1.self_attn.out_proj.weight
Copied param enc_a.layers.1.self_attn.out_proj.bias
Copied param enc_a.layers.1.linear1.weight
Copied param enc_a.layers.1.linear1.bias
Copied param enc_a.layers.1.linear2.weight
Copied param enc_a.layers.1.linear2.bias
Copied param enc_a.layers.1.norm1.weight
Copied param enc_a.layers.1.norm1.bias
Copied param enc_a.layers.1.norm2.weight
Copied param enc_a.layers.1.norm2.bias
Copied param enc_a.layers.2.self_attn.in_proj_weight
Copied param enc_a.layers.2.self_attn.in_proj_bias
Copied param enc_a.layers.2.self_attn.out_proj.weight
Copied param enc_a.layers.2.self_attn.out_proj.bias
Copied param enc_a.layers.2.linear1.weight
Copied param enc_a.layers.2.linear1.bias
Copied param enc_a.layers.2.linear2.weight
Copied param enc_a.layers.2.linear2.bias
Copied param enc_a.layers.2.norm1.weight
Copied param enc_a.layers.2.norm1.bias
Copied param enc_a.layers.2.norm2.weight
Copied param enc_a.layers.2.norm2.bias
Copied param enc_v.layers.0.self_attn.in_proj_weight
Copied param enc_v.layers.0.self_attn.in_proj_bias
Copied param enc_v.layers.0.self_attn.out_proj.weight
Copied param enc_v.layers.0.self_attn.out_proj.bias
Copied param enc_v.layers.0.linear1.weight
Copied param enc_v.layers.0.linear1.bias
Copied param enc_v.layers.0.linear2.weight
Copied param enc_v.layers.0.linear2.bias
Copied param enc_v.layers.0.norm1.weight
Copied param enc_v.layers.0.norm1.bias
Copied param enc_v.layers.0.norm2.weight
Copied param enc_v.layers.0.norm2.bias
Copied param enc_v.layers.1.self_attn.in_proj_weight
Copied param enc_v.layers.1.self_attn.in_proj_bias
Copied param enc_v.layers.1.self_attn.out_proj.weight
Copied param enc_v.layers.1.self_attn.out_proj.bias
Copied param enc_v.layers.1.linear1.weight
Copied param enc_v.layers.1.linear1.bias
Copied param enc_v.layers.1.linear2.weight
Copied param enc_v.layers.1.linear2.bias
Copied param enc_v.layers.1.norm1.weight
Copied param enc_v.layers.1.norm1.bias
Copied param enc_v.layers.1.norm2.weight
Copied param enc_v.layers.1.norm2.bias
Copied param enc_v.layers.2.self_attn.in_proj_weight
Copied param enc_v.layers.2.self_attn.in_proj_bias
Copied param enc_v.layers.2.self_attn.out_proj.weight
Copied param enc_v.layers.2.self_attn.out_proj.bias
Copied param enc_v.layers.2.linear1.weight
Copied param enc_v.layers.2.linear1.bias
Copied param enc_v.layers.2.linear2.weight
Copied param enc_v.layers.2.linear2.bias
Copied param enc_v.layers.2.norm1.weight
Copied param enc_v.layers.2.norm1.bias
Copied param enc_v.layers.2.norm2.weight
Copied param enc_v.layers.2.norm2.bias
Copied param fusion.weight
Copied param fusion.bias
Copied param clf.weight
Copied param clf.bias
------------------ Adding LNorm ------------------------
ongoing with msalm
7.ca_layer.alpha_1
7.ca_layer.alpha_2
7.ca_layer.audio_expert.attn.W_q.weight
7.ca_layer.audio_expert.attn.W_kv.weight
7.ca_layer.audio_expert.attn.W_o.weight
7.ca_layer.audio_expert.attn.gate_linear.weight
7.ca_layer.visual_expert.attn.W_q.weight
7.ca_layer.visual_expert.attn.W_kv.weight
7.ca_layer.visual_expert.attn.W_o.weight
7.ca_layer.visual_expert.attn.gate_linear.weight
7.ca_layer.av_expert.attn.W_q.weight
7.ca_layer.av_expert.attn.W_kv.weight
7.ca_layer.av_expert.attn.W_o.weight
7.ca_layer.av_expert.attn.gate_linear.weight
7.ca_layer.ln_1.weight
7.ca_layer.ln_1.bias
7.ca_layer.ln_2.weight
7.ca_layer.ln_2.bias
7.ca_layer.mlp.c_fc.weight
7.ca_layer.mlp.c_fc.bias
7.ca_layer.mlp.c_proj.weight
7.ca_layer.mlp.c_proj.bias
14.ca_layer.alpha_1
14.ca_layer.alpha_2
14.ca_layer.audio_expert.attn.W_q.weight
14.ca_layer.audio_expert.attn.W_kv.weight
14.ca_layer.audio_expert.attn.W_o.weight
14.ca_layer.audio_expert.attn.gate_linear.weight
14.ca_layer.visual_expert.attn.W_q.weight
14.ca_layer.visual_expert.attn.W_kv.weight
14.ca_layer.visual_expert.attn.W_o.weight
14.ca_layer.visual_expert.attn.gate_linear.weight
14.ca_layer.av_expert.attn.W_q.weight
14.ca_layer.av_expert.attn.W_kv.weight
14.ca_layer.av_expert.attn.W_o.weight
14.ca_layer.av_expert.attn.gate_linear.weight
14.ca_layer.ln_1.weight
14.ca_layer.ln_1.bias
14.ca_layer.ln_2.weight
14.ca_layer.ln_2.bias
14.ca_layer.mlp.c_fc.weight
14.ca_layer.mlp.c_fc.bias
14.ca_layer.mlp.c_proj.weight
14.ca_layer.mlp.c_proj.bias
21.ca_layer.alpha_1
21.ca_layer.alpha_2
21.ca_layer.audio_expert.attn.W_q.weight
21.ca_layer.audio_expert.attn.W_kv.weight
21.ca_layer.audio_expert.attn.W_o.weight
21.ca_layer.audio_expert.attn.gate_linear.weight
21.ca_layer.visual_expert.attn.W_q.weight
21.ca_layer.visual_expert.attn.W_kv.weight
21.ca_layer.visual_expert.attn.W_o.weight
21.ca_layer.visual_expert.attn.gate_linear.weight
21.ca_layer.av_expert.attn.W_q.weight
21.ca_layer.av_expert.attn.W_kv.weight
21.ca_layer.av_expert.attn.W_o.weight
21.ca_layer.av_expert.attn.gate_linear.weight
21.ca_layer.ln_1.weight
21.ca_layer.ln_1.bias
21.ca_layer.ln_2.weight
21.ca_layer.ln_2.bias
21.ca_layer.mlp.c_fc.weight
21.ca_layer.mlp.c_fc.bias
21.ca_layer.mlp.c_proj.weight
21.ca_layer.mlp.c_proj.bias
28.ca_layer.alpha_1
28.ca_layer.alpha_2
28.ca_layer.audio_expert.attn.W_q.weight
28.ca_layer.audio_expert.attn.W_kv.weight
28.ca_layer.audio_expert.attn.W_o.weight
28.ca_layer.audio_expert.attn.gate_linear.weight
28.ca_layer.visual_expert.attn.W_q.weight
28.ca_layer.visual_expert.attn.W_kv.weight
28.ca_layer.visual_expert.attn.W_o.weight
28.ca_layer.visual_expert.attn.gate_linear.weight
28.ca_layer.av_expert.attn.W_q.weight
28.ca_layer.av_expert.attn.W_kv.weight
28.ca_layer.av_expert.attn.W_o.weight
28.ca_layer.av_expert.attn.gate_linear.weight
28.ca_layer.ln_1.weight
28.ca_layer.ln_1.bias
28.ca_layer.ln_2.weight
28.ca_layer.ln_2.bias
28.ca_layer.mlp.c_fc.weight
28.ca_layer.mlp.c_fc.bias
28.ca_layer.mlp.c_proj.weight
28.ca_layer.mlp.c_proj.bias
35.ca_layer.alpha_1
35.ca_layer.alpha_2
35.ca_layer.audio_expert.attn.W_q.weight
35.ca_layer.audio_expert.attn.W_kv.weight
35.ca_layer.audio_expert.attn.W_o.weight
35.ca_layer.audio_expert.attn.gate_linear.weight
35.ca_layer.visual_expert.attn.W_q.weight
35.ca_layer.visual_expert.attn.W_kv.weight
35.ca_layer.visual_expert.attn.W_o.weight
35.ca_layer.visual_expert.attn.gate_linear.weight
35.ca_layer.av_expert.attn.W_q.weight
35.ca_layer.av_expert.attn.W_kv.weight
35.ca_layer.av_expert.attn.W_o.weight
35.ca_layer.av_expert.attn.gate_linear.weight
35.ca_layer.ln_1.weight
35.ca_layer.ln_1.bias
35.ca_layer.ln_2.weight
35.ca_layer.ln_2.bias
35.ca_layer.mlp.c_fc.weight
35.ca_layer.mlp.c_fc.bias
35.ca_layer.mlp.c_proj.weight
35.ca_layer.mlp.c_proj.bias
0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.W_task.0.weight
Model.W_task.0.bias
Model.W_task.1.weight
Model.W_task.1.bias
Model.W_task.3.weight
Model.W_task.3.bias
Model.W_bn.weight
Model.W_bn.bias
Model.W_text.weight
Model.W_text.bias
Model.W_av.weight
Model.W_av.bias
Model.av_encoder.proj_a.weight
Model.av_encoder.proj_v.weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.0.linear1.weight
Model.av_encoder.enc_a.layers.0.linear1.bias
Model.av_encoder.enc_a.layers.0.linear2.weight
Model.av_encoder.enc_a.layers.0.linear2.bias
Model.av_encoder.enc_a.layers.0.norm1.weight
Model.av_encoder.enc_a.layers.0.norm1.bias
Model.av_encoder.enc_a.layers.0.norm2.weight
Model.av_encoder.enc_a.layers.0.norm2.bias
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.1.linear1.weight
Model.av_encoder.enc_a.layers.1.linear1.bias
Model.av_encoder.enc_a.layers.1.linear2.weight
Model.av_encoder.enc_a.layers.1.linear2.bias
Model.av_encoder.enc_a.layers.1.norm1.weight
Model.av_encoder.enc_a.layers.1.norm1.bias
Model.av_encoder.enc_a.layers.1.norm2.weight
Model.av_encoder.enc_a.layers.1.norm2.bias
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.2.linear1.weight
Model.av_encoder.enc_a.layers.2.linear1.bias
Model.av_encoder.enc_a.layers.2.linear2.weight
Model.av_encoder.enc_a.layers.2.linear2.bias
Model.av_encoder.enc_a.layers.2.norm1.weight
Model.av_encoder.enc_a.layers.2.norm1.bias
Model.av_encoder.enc_a.layers.2.norm2.weight
Model.av_encoder.enc_a.layers.2.norm2.bias
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.0.linear1.weight
Model.av_encoder.enc_v.layers.0.linear1.bias
Model.av_encoder.enc_v.layers.0.linear2.weight
Model.av_encoder.enc_v.layers.0.linear2.bias
Model.av_encoder.enc_v.layers.0.norm1.weight
Model.av_encoder.enc_v.layers.0.norm1.bias
Model.av_encoder.enc_v.layers.0.norm2.weight
Model.av_encoder.enc_v.layers.0.norm2.bias
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.1.linear1.weight
Model.av_encoder.enc_v.layers.1.linear1.bias
Model.av_encoder.enc_v.layers.1.linear2.weight
Model.av_encoder.enc_v.layers.1.linear2.bias
Model.av_encoder.enc_v.layers.1.norm1.weight
Model.av_encoder.enc_v.layers.1.norm1.bias
Model.av_encoder.enc_v.layers.1.norm2.weight
Model.av_encoder.enc_v.layers.1.norm2.bias
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.2.linear1.weight
Model.av_encoder.enc_v.layers.2.linear1.bias
Model.av_encoder.enc_v.layers.2.linear2.weight
Model.av_encoder.enc_v.layers.2.linear2.bias
Model.av_encoder.enc_v.layers.2.norm1.weight
Model.av_encoder.enc_v.layers.2.norm1.bias
Model.av_encoder.enc_v.layers.2.norm2.weight
Model.av_encoder.enc_v.layers.2.norm2.bias
Model.av_encoder.fusion.weight
Model.av_encoder.fusion.bias
Model.av_encoder.clf.weight
Model.av_encoder.clf.bias
Model.LN.weight
Model.LN.bias
The total number of trainable parameters is 140.73 M
Model.lang_encoder.transformer.wte.0.embedding.weight
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Using grad with decay in Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wpe.0.positional.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.ln_f.weight
Model.lang_encoder.transformer.ln_f.bias
Model.W_task.0.weight
Using grad with decay in Model.W_task.0.weight
Model.W_task.0.bias
Using grad with no decay in Model.W_task.0.bias
Model.W_task.1.weight
Using grad with decay in Model.W_task.1.weight
Model.W_task.1.bias
Using grad with no decay in Model.W_task.1.bias
Model.W_task.3.weight
Using grad with decay in Model.W_task.3.weight
Model.W_task.3.bias
Using grad with no decay in Model.W_task.3.bias
Model.W_bn.weight
Using grad with decay in Model.W_bn.weight
Model.W_bn.bias
Using grad with no decay in Model.W_bn.bias
Model.W_text.weight
Using grad with decay in Model.W_text.weight
Model.W_text.bias
Using grad with no decay in Model.W_text.bias
Model.W_av.weight
Using grad with decay in Model.W_av.weight
Model.W_av.bias
Using grad with no decay in Model.W_av.bias
Model.LN.weight
Using grad with decay in Model.LN.weight
Model.LN.bias
Using grad with no decay in Model.LN.bias
Will be using warmup for 63 steps
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0017], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0041], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0029], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0011], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0030], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0008], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0019], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0004], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0015], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0016], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0072], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0131], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0101], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0028], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0060], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0040], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0030], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0013], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0015], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0089], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0104], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0220], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0140], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0017], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0068], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0078], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0033], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0042], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0020], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0162], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0094], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0282], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0174], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0043], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0074], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0145], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0044], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0097], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0028], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0257], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0143], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0304], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0212], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0120], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0090], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0218], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0062], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0165], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0039], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0347], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0184], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0301], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0237], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0211], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0106], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0289], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0079], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0227], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0051], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0431], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0225], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0289], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0261], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0295], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0112], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0365], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0087], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0296], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0063], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0512], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0260], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0265], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0280], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0372], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0128], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0429], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0110], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0353], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0076], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0591], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0284], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0244], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0306], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0442], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0132], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0490], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0128], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0408], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0087], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0659], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0312], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0241], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0331], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0508], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0143], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0546], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0149], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0465], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0099], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0726], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0346], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0222], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0359], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0565], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0157], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0598], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0166], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0514], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0111], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0785], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0374], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0200], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0382], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0613], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0168], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0646], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0187], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0561], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0125], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0838], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0394], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0176], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0393], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0654], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0176], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0686], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0201], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0599], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0135], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0882], device='cuda:0', requires_grad=True)
***************** Loading Model from checkpoints/thesis-mosei/msalm-mosei-1992.pth
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0104], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0220], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0140], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0017], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0068], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0078], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0033], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0042], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0020], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0162], device='cuda:0', requires_grad=True)
Deleting stored model from checkpoints/thesis-mosei/msalm-mosei-1992.pth
Loading HF datasets
---------------------- Ongoing with TRAIN data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(16326, 500, 74)
(16326, 500, 35)
---------------------- Ongoing with VALID data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(1871, 500, 74)
(1871, 500, 35)
---------------------- Ongoing with TEST data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(4659, 500, 74)
(4659, 500, 35)
Ongoing with num_workers=2
ca list is: [7, 14, 21, 28, 35]
initializing SoftPerm
Ongoing with ----- sigmoid ----- gating
idx is 0
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 1
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 2
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 3
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 4
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Parsing decoder block: 0
Parsing decoder block: 1
Parsing decoder block: 2
Parsing decoder block: 3
Parsing decoder block: 4
Parsing decoder block: 5
Parsing decoder block: 6
Parsing decoder block: 7
COpying---------------------------------
Parsing decoder block: 8
Parsing decoder block: 9
Parsing decoder block: 10
Parsing decoder block: 11
Parsing decoder block: 12
Parsing decoder block: 13
Parsing decoder block: 14
COpying---------------------------------
Parsing decoder block: 15
Parsing decoder block: 16
Parsing decoder block: 17
Parsing decoder block: 18
Parsing decoder block: 19
Parsing decoder block: 20
Parsing decoder block: 21
COpying---------------------------------
Parsing decoder block: 22
Parsing decoder block: 23
Parsing decoder block: 24
Parsing decoder block: 25
Parsing decoder block: 26
Parsing decoder block: 27
Parsing decoder block: 28
COpying---------------------------------
Parsing decoder block: 29
Parsing decoder block: 30
Parsing decoder block: 31
Parsing decoder block: 32
Parsing decoder block: 33
Parsing decoder block: 34
Parsing decoder block: 35
COpying---------------------------------
No normalization is used
----------------->>> Pretrained AudioVisual Encoder <<<<<----------------
No normalization is used
----------------------- Loading AV encoder from /leonardo_work/EUHPC_A04_051/alexfil/DeepMLF-Reprod/checkpoints/bienc-mosei-1990/bienc-mosei-1990.pth
Copied param embed_positions_a._float_tensor
Copied param embed_positions_v._float_tensor
Copied param proj_a.weight
Copied param proj_v.weight
Copied param enc_a.layers.0.self_attn.in_proj_weight
Copied param enc_a.layers.0.self_attn.in_proj_bias
Copied param enc_a.layers.0.self_attn.out_proj.weight
Copied param enc_a.layers.0.self_attn.out_proj.bias
Copied param enc_a.layers.0.linear1.weight
Copied param enc_a.layers.0.linear1.bias
Copied param enc_a.layers.0.linear2.weight
Copied param enc_a.layers.0.linear2.bias
Copied param enc_a.layers.0.norm1.weight
Copied param enc_a.layers.0.norm1.bias
Copied param enc_a.layers.0.norm2.weight
Copied param enc_a.layers.0.norm2.bias
Copied param enc_a.layers.1.self_attn.in_proj_weight
Copied param enc_a.layers.1.self_attn.in_proj_bias
Copied param enc_a.layers.1.self_attn.out_proj.weight
Copied param enc_a.layers.1.self_attn.out_proj.bias
Copied param enc_a.layers.1.linear1.weight
Copied param enc_a.layers.1.linear1.bias
Copied param enc_a.layers.1.linear2.weight
Copied param enc_a.layers.1.linear2.bias
Copied param enc_a.layers.1.norm1.weight
Copied param enc_a.layers.1.norm1.bias
Copied param enc_a.layers.1.norm2.weight
Copied param enc_a.layers.1.norm2.bias
Copied param enc_a.layers.2.self_attn.in_proj_weight
Copied param enc_a.layers.2.self_attn.in_proj_bias
Copied param enc_a.layers.2.self_attn.out_proj.weight
Copied param enc_a.layers.2.self_attn.out_proj.bias
Copied param enc_a.layers.2.linear1.weight
Copied param enc_a.layers.2.linear1.bias
Copied param enc_a.layers.2.linear2.weight
Copied param enc_a.layers.2.linear2.bias
Copied param enc_a.layers.2.norm1.weight
Copied param enc_a.layers.2.norm1.bias
Copied param enc_a.layers.2.norm2.weight
Copied param enc_a.layers.2.norm2.bias
Copied param enc_v.layers.0.self_attn.in_proj_weight
Copied param enc_v.layers.0.self_attn.in_proj_bias
Copied param enc_v.layers.0.self_attn.out_proj.weight
Copied param enc_v.layers.0.self_attn.out_proj.bias
Copied param enc_v.layers.0.linear1.weight
Copied param enc_v.layers.0.linear1.bias
Copied param enc_v.layers.0.linear2.weight
Copied param enc_v.layers.0.linear2.bias
Copied param enc_v.layers.0.norm1.weight
Copied param enc_v.layers.0.norm1.bias
Copied param enc_v.layers.0.norm2.weight
Copied param enc_v.layers.0.norm2.bias
Copied param enc_v.layers.1.self_attn.in_proj_weight
Copied param enc_v.layers.1.self_attn.in_proj_bias
Copied param enc_v.layers.1.self_attn.out_proj.weight
Copied param enc_v.layers.1.self_attn.out_proj.bias
Copied param enc_v.layers.1.linear1.weight
Copied param enc_v.layers.1.linear1.bias
Copied param enc_v.layers.1.linear2.weight
Copied param enc_v.layers.1.linear2.bias
Copied param enc_v.layers.1.norm1.weight
Copied param enc_v.layers.1.norm1.bias
Copied param enc_v.layers.1.norm2.weight
Copied param enc_v.layers.1.norm2.bias
Copied param enc_v.layers.2.self_attn.in_proj_weight
Copied param enc_v.layers.2.self_attn.in_proj_bias
Copied param enc_v.layers.2.self_attn.out_proj.weight
Copied param enc_v.layers.2.self_attn.out_proj.bias
Copied param enc_v.layers.2.linear1.weight
Copied param enc_v.layers.2.linear1.bias
Copied param enc_v.layers.2.linear2.weight
Copied param enc_v.layers.2.linear2.bias
Copied param enc_v.layers.2.norm1.weight
Copied param enc_v.layers.2.norm1.bias
Copied param enc_v.layers.2.norm2.weight
Copied param enc_v.layers.2.norm2.bias
Copied param fusion.weight
Copied param fusion.bias
Copied param clf.weight
Copied param clf.bias
------------------ Adding LNorm ------------------------
ongoing with msalm
7.ca_layer.alpha_1
7.ca_layer.alpha_2
7.ca_layer.audio_expert.attn.W_q.weight
7.ca_layer.audio_expert.attn.W_kv.weight
7.ca_layer.audio_expert.attn.W_o.weight
7.ca_layer.audio_expert.attn.gate_linear.weight
7.ca_layer.visual_expert.attn.W_q.weight
7.ca_layer.visual_expert.attn.W_kv.weight
7.ca_layer.visual_expert.attn.W_o.weight
7.ca_layer.visual_expert.attn.gate_linear.weight
7.ca_layer.av_expert.attn.W_q.weight
7.ca_layer.av_expert.attn.W_kv.weight
7.ca_layer.av_expert.attn.W_o.weight
7.ca_layer.av_expert.attn.gate_linear.weight
7.ca_layer.ln_1.weight
7.ca_layer.ln_1.bias
7.ca_layer.ln_2.weight
7.ca_layer.ln_2.bias
7.ca_layer.mlp.c_fc.weight
7.ca_layer.mlp.c_fc.bias
7.ca_layer.mlp.c_proj.weight
7.ca_layer.mlp.c_proj.bias
14.ca_layer.alpha_1
14.ca_layer.alpha_2
14.ca_layer.audio_expert.attn.W_q.weight
14.ca_layer.audio_expert.attn.W_kv.weight
14.ca_layer.audio_expert.attn.W_o.weight
14.ca_layer.audio_expert.attn.gate_linear.weight
14.ca_layer.visual_expert.attn.W_q.weight
14.ca_layer.visual_expert.attn.W_kv.weight
14.ca_layer.visual_expert.attn.W_o.weight
14.ca_layer.visual_expert.attn.gate_linear.weight
14.ca_layer.av_expert.attn.W_q.weight
14.ca_layer.av_expert.attn.W_kv.weight
14.ca_layer.av_expert.attn.W_o.weight
14.ca_layer.av_expert.attn.gate_linear.weight
14.ca_layer.ln_1.weight
14.ca_layer.ln_1.bias
14.ca_layer.ln_2.weight
14.ca_layer.ln_2.bias
14.ca_layer.mlp.c_fc.weight
14.ca_layer.mlp.c_fc.bias
14.ca_layer.mlp.c_proj.weight
14.ca_layer.mlp.c_proj.bias
21.ca_layer.alpha_1
21.ca_layer.alpha_2
21.ca_layer.audio_expert.attn.W_q.weight
21.ca_layer.audio_expert.attn.W_kv.weight
21.ca_layer.audio_expert.attn.W_o.weight
21.ca_layer.audio_expert.attn.gate_linear.weight
21.ca_layer.visual_expert.attn.W_q.weight
21.ca_layer.visual_expert.attn.W_kv.weight
21.ca_layer.visual_expert.attn.W_o.weight
21.ca_layer.visual_expert.attn.gate_linear.weight
21.ca_layer.av_expert.attn.W_q.weight
21.ca_layer.av_expert.attn.W_kv.weight
21.ca_layer.av_expert.attn.W_o.weight
21.ca_layer.av_expert.attn.gate_linear.weight
21.ca_layer.ln_1.weight
21.ca_layer.ln_1.bias
21.ca_layer.ln_2.weight
21.ca_layer.ln_2.bias
21.ca_layer.mlp.c_fc.weight
21.ca_layer.mlp.c_fc.bias
21.ca_layer.mlp.c_proj.weight
21.ca_layer.mlp.c_proj.bias
28.ca_layer.alpha_1
28.ca_layer.alpha_2
28.ca_layer.audio_expert.attn.W_q.weight
28.ca_layer.audio_expert.attn.W_kv.weight
28.ca_layer.audio_expert.attn.W_o.weight
28.ca_layer.audio_expert.attn.gate_linear.weight
28.ca_layer.visual_expert.attn.W_q.weight
28.ca_layer.visual_expert.attn.W_kv.weight
28.ca_layer.visual_expert.attn.W_o.weight
28.ca_layer.visual_expert.attn.gate_linear.weight
28.ca_layer.av_expert.attn.W_q.weight
28.ca_layer.av_expert.attn.W_kv.weight
28.ca_layer.av_expert.attn.W_o.weight
28.ca_layer.av_expert.attn.gate_linear.weight
28.ca_layer.ln_1.weight
28.ca_layer.ln_1.bias
28.ca_layer.ln_2.weight
28.ca_layer.ln_2.bias
28.ca_layer.mlp.c_fc.weight
28.ca_layer.mlp.c_fc.bias
28.ca_layer.mlp.c_proj.weight
28.ca_layer.mlp.c_proj.bias
35.ca_layer.alpha_1
35.ca_layer.alpha_2
35.ca_layer.audio_expert.attn.W_q.weight
35.ca_layer.audio_expert.attn.W_kv.weight
35.ca_layer.audio_expert.attn.W_o.weight
35.ca_layer.audio_expert.attn.gate_linear.weight
35.ca_layer.visual_expert.attn.W_q.weight
35.ca_layer.visual_expert.attn.W_kv.weight
35.ca_layer.visual_expert.attn.W_o.weight
35.ca_layer.visual_expert.attn.gate_linear.weight
35.ca_layer.av_expert.attn.W_q.weight
35.ca_layer.av_expert.attn.W_kv.weight
35.ca_layer.av_expert.attn.W_o.weight
35.ca_layer.av_expert.attn.gate_linear.weight
35.ca_layer.ln_1.weight
35.ca_layer.ln_1.bias
35.ca_layer.ln_2.weight
35.ca_layer.ln_2.bias
35.ca_layer.mlp.c_fc.weight
35.ca_layer.mlp.c_fc.bias
35.ca_layer.mlp.c_proj.weight
35.ca_layer.mlp.c_proj.bias
0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.W_task.0.weight
Model.W_task.0.bias
Model.W_task.1.weight
Model.W_task.1.bias
Model.W_task.3.weight
Model.W_task.3.bias
Model.W_bn.weight
Model.W_bn.bias
Model.W_text.weight
Model.W_text.bias
Model.W_av.weight
Model.W_av.bias
Model.av_encoder.proj_a.weight
Model.av_encoder.proj_v.weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.0.linear1.weight
Model.av_encoder.enc_a.layers.0.linear1.bias
Model.av_encoder.enc_a.layers.0.linear2.weight
Model.av_encoder.enc_a.layers.0.linear2.bias
Model.av_encoder.enc_a.layers.0.norm1.weight
Model.av_encoder.enc_a.layers.0.norm1.bias
Model.av_encoder.enc_a.layers.0.norm2.weight
Model.av_encoder.enc_a.layers.0.norm2.bias
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.1.linear1.weight
Model.av_encoder.enc_a.layers.1.linear1.bias
Model.av_encoder.enc_a.layers.1.linear2.weight
Model.av_encoder.enc_a.layers.1.linear2.bias
Model.av_encoder.enc_a.layers.1.norm1.weight
Model.av_encoder.enc_a.layers.1.norm1.bias
Model.av_encoder.enc_a.layers.1.norm2.weight
Model.av_encoder.enc_a.layers.1.norm2.bias
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.2.linear1.weight
Model.av_encoder.enc_a.layers.2.linear1.bias
Model.av_encoder.enc_a.layers.2.linear2.weight
Model.av_encoder.enc_a.layers.2.linear2.bias
Model.av_encoder.enc_a.layers.2.norm1.weight
Model.av_encoder.enc_a.layers.2.norm1.bias
Model.av_encoder.enc_a.layers.2.norm2.weight
Model.av_encoder.enc_a.layers.2.norm2.bias
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.0.linear1.weight
Model.av_encoder.enc_v.layers.0.linear1.bias
Model.av_encoder.enc_v.layers.0.linear2.weight
Model.av_encoder.enc_v.layers.0.linear2.bias
Model.av_encoder.enc_v.layers.0.norm1.weight
Model.av_encoder.enc_v.layers.0.norm1.bias
Model.av_encoder.enc_v.layers.0.norm2.weight
Model.av_encoder.enc_v.layers.0.norm2.bias
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.1.linear1.weight
Model.av_encoder.enc_v.layers.1.linear1.bias
Model.av_encoder.enc_v.layers.1.linear2.weight
Model.av_encoder.enc_v.layers.1.linear2.bias
Model.av_encoder.enc_v.layers.1.norm1.weight
Model.av_encoder.enc_v.layers.1.norm1.bias
Model.av_encoder.enc_v.layers.1.norm2.weight
Model.av_encoder.enc_v.layers.1.norm2.bias
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.2.linear1.weight
Model.av_encoder.enc_v.layers.2.linear1.bias
Model.av_encoder.enc_v.layers.2.linear2.weight
Model.av_encoder.enc_v.layers.2.linear2.bias
Model.av_encoder.enc_v.layers.2.norm1.weight
Model.av_encoder.enc_v.layers.2.norm1.bias
Model.av_encoder.enc_v.layers.2.norm2.weight
Model.av_encoder.enc_v.layers.2.norm2.bias
Model.av_encoder.fusion.weight
Model.av_encoder.fusion.bias
Model.av_encoder.clf.weight
Model.av_encoder.clf.bias
Model.LN.weight
Model.LN.bias
The total number of trainable parameters is 140.73 M
Model.lang_encoder.transformer.wte.0.embedding.weight
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Using grad with decay in Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wpe.0.positional.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.ln_f.weight
Model.lang_encoder.transformer.ln_f.bias
Model.W_task.0.weight
Using grad with decay in Model.W_task.0.weight
Model.W_task.0.bias
Using grad with no decay in Model.W_task.0.bias
Model.W_task.1.weight
Using grad with decay in Model.W_task.1.weight
Model.W_task.1.bias
Using grad with no decay in Model.W_task.1.bias
Model.W_task.3.weight
Using grad with decay in Model.W_task.3.weight
Model.W_task.3.bias
Using grad with no decay in Model.W_task.3.bias
Model.W_bn.weight
Using grad with decay in Model.W_bn.weight
Model.W_bn.bias
Using grad with no decay in Model.W_bn.bias
Model.W_text.weight
Using grad with decay in Model.W_text.weight
Model.W_text.bias
Using grad with no decay in Model.W_text.bias
Model.W_av.weight
Using grad with decay in Model.W_av.weight
Model.W_av.bias
Using grad with no decay in Model.W_av.bias
Model.LN.weight
Using grad with decay in Model.LN.weight
Model.LN.bias
Using grad with no decay in Model.LN.bias
Will be using warmup for 63 steps
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0013], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0036], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0028], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0003], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0017], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0018], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0018], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0006], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0013], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0015], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0067], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0122], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0107], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0019], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0050], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0048], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0027], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0027], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0018], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0093], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0080], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0204], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0139], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0002], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0064], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0090], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0030], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0058], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0018], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0170], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0089], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0276], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0161], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0057], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0064], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0149], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0033], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0108], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0019], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0248], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0111], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0322], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0169], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0136], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0080], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0219], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0046], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0177], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0035], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0336], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0150], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0341], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0181], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0221], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0090], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0294], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0058], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0244], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0046], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0418], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0199], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0341], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0196], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0306], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0109], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0369], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0079], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0315], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0061], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0501], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0244], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0327], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0212], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0382], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0131], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0436], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0097], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0380], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0074], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0581], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0277], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0299], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0228], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0453], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0150], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0497], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0123], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0440], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0091], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0654], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0307], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0271], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0236], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0518], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0159], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0559], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0149], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0500], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0108], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0723], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0338], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0240], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0243], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0577], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0179], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0613], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0170], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0556], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0127], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0786], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0363], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0219], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0251], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0626], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0201], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0660], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0188], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0602], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0143], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0838], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0387], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0199], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0259], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0666], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0221], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0699], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0210], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0640], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0160], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0882], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0410], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0179], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0267], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0697], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0231], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0727], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0227], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0669], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0172], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0918], device='cuda:0', requires_grad=True)
***************** Loading Model from checkpoints/thesis-mosei/msalm-mosei-1993.pth
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0089], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0276], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0161], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0057], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0064], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0149], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0033], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0108], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0019], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0248], device='cuda:0', requires_grad=True)
Deleting stored model from checkpoints/thesis-mosei/msalm-mosei-1993.pth
Loading HF datasets
---------------------- Ongoing with TRAIN data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(16326, 500, 74)
(16326, 500, 35)
---------------------- Ongoing with VALID data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(1871, 500, 74)
(1871, 500, 35)
---------------------- Ongoing with TEST data split -----------------------------
Using GPT LM
All the sequence lengths are L:50, A:500, V:375
Preprocessing custom M-SENA pickles
audio features are (16326, 500, 74)
vision features are (16326, 500, 35)
Starting processing --------------------->
(4659, 500, 74)
(4659, 500, 35)
Ongoing with num_workers=2
ca list is: [7, 14, 21, 28, 35]
initializing SoftPerm
Ongoing with ----- sigmoid ----- gating
idx is 0
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 1
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 2
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 3
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Ongoing with ----- sigmoid ----- gating
idx is 4
[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
Parsing decoder block: 0
Parsing decoder block: 1
Parsing decoder block: 2
Parsing decoder block: 3
Parsing decoder block: 4
Parsing decoder block: 5
Parsing decoder block: 6
Parsing decoder block: 7
COpying---------------------------------
Parsing decoder block: 8
Parsing decoder block: 9
Parsing decoder block: 10
Parsing decoder block: 11
Parsing decoder block: 12
Parsing decoder block: 13
Parsing decoder block: 14
COpying---------------------------------
Parsing decoder block: 15
Parsing decoder block: 16
Parsing decoder block: 17
Parsing decoder block: 18
Parsing decoder block: 19
Parsing decoder block: 20
Parsing decoder block: 21
COpying---------------------------------
Parsing decoder block: 22
Parsing decoder block: 23
Parsing decoder block: 24
Parsing decoder block: 25
Parsing decoder block: 26
Parsing decoder block: 27
Parsing decoder block: 28
COpying---------------------------------
Parsing decoder block: 29
Parsing decoder block: 30
Parsing decoder block: 31
Parsing decoder block: 32
Parsing decoder block: 33
Parsing decoder block: 34
Parsing decoder block: 35
COpying---------------------------------
No normalization is used
----------------->>> Pretrained AudioVisual Encoder <<<<<----------------
No normalization is used
----------------------- Loading AV encoder from /leonardo_work/EUHPC_A04_051/alexfil/DeepMLF-Reprod/checkpoints/bienc-mosei-1990/bienc-mosei-1990.pth
Copied param embed_positions_a._float_tensor
Copied param embed_positions_v._float_tensor
Copied param proj_a.weight
Copied param proj_v.weight
Copied param enc_a.layers.0.self_attn.in_proj_weight
Copied param enc_a.layers.0.self_attn.in_proj_bias
Copied param enc_a.layers.0.self_attn.out_proj.weight
Copied param enc_a.layers.0.self_attn.out_proj.bias
Copied param enc_a.layers.0.linear1.weight
Copied param enc_a.layers.0.linear1.bias
Copied param enc_a.layers.0.linear2.weight
Copied param enc_a.layers.0.linear2.bias
Copied param enc_a.layers.0.norm1.weight
Copied param enc_a.layers.0.norm1.bias
Copied param enc_a.layers.0.norm2.weight
Copied param enc_a.layers.0.norm2.bias
Copied param enc_a.layers.1.self_attn.in_proj_weight
Copied param enc_a.layers.1.self_attn.in_proj_bias
Copied param enc_a.layers.1.self_attn.out_proj.weight
Copied param enc_a.layers.1.self_attn.out_proj.bias
Copied param enc_a.layers.1.linear1.weight
Copied param enc_a.layers.1.linear1.bias
Copied param enc_a.layers.1.linear2.weight
Copied param enc_a.layers.1.linear2.bias
Copied param enc_a.layers.1.norm1.weight
Copied param enc_a.layers.1.norm1.bias
Copied param enc_a.layers.1.norm2.weight
Copied param enc_a.layers.1.norm2.bias
Copied param enc_a.layers.2.self_attn.in_proj_weight
Copied param enc_a.layers.2.self_attn.in_proj_bias
Copied param enc_a.layers.2.self_attn.out_proj.weight
Copied param enc_a.layers.2.self_attn.out_proj.bias
Copied param enc_a.layers.2.linear1.weight
Copied param enc_a.layers.2.linear1.bias
Copied param enc_a.layers.2.linear2.weight
Copied param enc_a.layers.2.linear2.bias
Copied param enc_a.layers.2.norm1.weight
Copied param enc_a.layers.2.norm1.bias
Copied param enc_a.layers.2.norm2.weight
Copied param enc_a.layers.2.norm2.bias
Copied param enc_v.layers.0.self_attn.in_proj_weight
Copied param enc_v.layers.0.self_attn.in_proj_bias
Copied param enc_v.layers.0.self_attn.out_proj.weight
Copied param enc_v.layers.0.self_attn.out_proj.bias
Copied param enc_v.layers.0.linear1.weight
Copied param enc_v.layers.0.linear1.bias
Copied param enc_v.layers.0.linear2.weight
Copied param enc_v.layers.0.linear2.bias
Copied param enc_v.layers.0.norm1.weight
Copied param enc_v.layers.0.norm1.bias
Copied param enc_v.layers.0.norm2.weight
Copied param enc_v.layers.0.norm2.bias
Copied param enc_v.layers.1.self_attn.in_proj_weight
Copied param enc_v.layers.1.self_attn.in_proj_bias
Copied param enc_v.layers.1.self_attn.out_proj.weight
Copied param enc_v.layers.1.self_attn.out_proj.bias
Copied param enc_v.layers.1.linear1.weight
Copied param enc_v.layers.1.linear1.bias
Copied param enc_v.layers.1.linear2.weight
Copied param enc_v.layers.1.linear2.bias
Copied param enc_v.layers.1.norm1.weight
Copied param enc_v.layers.1.norm1.bias
Copied param enc_v.layers.1.norm2.weight
Copied param enc_v.layers.1.norm2.bias
Copied param enc_v.layers.2.self_attn.in_proj_weight
Copied param enc_v.layers.2.self_attn.in_proj_bias
Copied param enc_v.layers.2.self_attn.out_proj.weight
Copied param enc_v.layers.2.self_attn.out_proj.bias
Copied param enc_v.layers.2.linear1.weight
Copied param enc_v.layers.2.linear1.bias
Copied param enc_v.layers.2.linear2.weight
Copied param enc_v.layers.2.linear2.bias
Copied param enc_v.layers.2.norm1.weight
Copied param enc_v.layers.2.norm1.bias
Copied param enc_v.layers.2.norm2.weight
Copied param enc_v.layers.2.norm2.bias
Copied param fusion.weight
Copied param fusion.bias
Copied param clf.weight
Copied param clf.bias
------------------ Adding LNorm ------------------------
ongoing with msalm
7.ca_layer.alpha_1
7.ca_layer.alpha_2
7.ca_layer.audio_expert.attn.W_q.weight
7.ca_layer.audio_expert.attn.W_kv.weight
7.ca_layer.audio_expert.attn.W_o.weight
7.ca_layer.audio_expert.attn.gate_linear.weight
7.ca_layer.visual_expert.attn.W_q.weight
7.ca_layer.visual_expert.attn.W_kv.weight
7.ca_layer.visual_expert.attn.W_o.weight
7.ca_layer.visual_expert.attn.gate_linear.weight
7.ca_layer.av_expert.attn.W_q.weight
7.ca_layer.av_expert.attn.W_kv.weight
7.ca_layer.av_expert.attn.W_o.weight
7.ca_layer.av_expert.attn.gate_linear.weight
7.ca_layer.ln_1.weight
7.ca_layer.ln_1.bias
7.ca_layer.ln_2.weight
7.ca_layer.ln_2.bias
7.ca_layer.mlp.c_fc.weight
7.ca_layer.mlp.c_fc.bias
7.ca_layer.mlp.c_proj.weight
7.ca_layer.mlp.c_proj.bias
14.ca_layer.alpha_1
14.ca_layer.alpha_2
14.ca_layer.audio_expert.attn.W_q.weight
14.ca_layer.audio_expert.attn.W_kv.weight
14.ca_layer.audio_expert.attn.W_o.weight
14.ca_layer.audio_expert.attn.gate_linear.weight
14.ca_layer.visual_expert.attn.W_q.weight
14.ca_layer.visual_expert.attn.W_kv.weight
14.ca_layer.visual_expert.attn.W_o.weight
14.ca_layer.visual_expert.attn.gate_linear.weight
14.ca_layer.av_expert.attn.W_q.weight
14.ca_layer.av_expert.attn.W_kv.weight
14.ca_layer.av_expert.attn.W_o.weight
14.ca_layer.av_expert.attn.gate_linear.weight
14.ca_layer.ln_1.weight
14.ca_layer.ln_1.bias
14.ca_layer.ln_2.weight
14.ca_layer.ln_2.bias
14.ca_layer.mlp.c_fc.weight
14.ca_layer.mlp.c_fc.bias
14.ca_layer.mlp.c_proj.weight
14.ca_layer.mlp.c_proj.bias
21.ca_layer.alpha_1
21.ca_layer.alpha_2
21.ca_layer.audio_expert.attn.W_q.weight
21.ca_layer.audio_expert.attn.W_kv.weight
21.ca_layer.audio_expert.attn.W_o.weight
21.ca_layer.audio_expert.attn.gate_linear.weight
21.ca_layer.visual_expert.attn.W_q.weight
21.ca_layer.visual_expert.attn.W_kv.weight
21.ca_layer.visual_expert.attn.W_o.weight
21.ca_layer.visual_expert.attn.gate_linear.weight
21.ca_layer.av_expert.attn.W_q.weight
21.ca_layer.av_expert.attn.W_kv.weight
21.ca_layer.av_expert.attn.W_o.weight
21.ca_layer.av_expert.attn.gate_linear.weight
21.ca_layer.ln_1.weight
21.ca_layer.ln_1.bias
21.ca_layer.ln_2.weight
21.ca_layer.ln_2.bias
21.ca_layer.mlp.c_fc.weight
21.ca_layer.mlp.c_fc.bias
21.ca_layer.mlp.c_proj.weight
21.ca_layer.mlp.c_proj.bias
28.ca_layer.alpha_1
28.ca_layer.alpha_2
28.ca_layer.audio_expert.attn.W_q.weight
28.ca_layer.audio_expert.attn.W_kv.weight
28.ca_layer.audio_expert.attn.W_o.weight
28.ca_layer.audio_expert.attn.gate_linear.weight
28.ca_layer.visual_expert.attn.W_q.weight
28.ca_layer.visual_expert.attn.W_kv.weight
28.ca_layer.visual_expert.attn.W_o.weight
28.ca_layer.visual_expert.attn.gate_linear.weight
28.ca_layer.av_expert.attn.W_q.weight
28.ca_layer.av_expert.attn.W_kv.weight
28.ca_layer.av_expert.attn.W_o.weight
28.ca_layer.av_expert.attn.gate_linear.weight
28.ca_layer.ln_1.weight
28.ca_layer.ln_1.bias
28.ca_layer.ln_2.weight
28.ca_layer.ln_2.bias
28.ca_layer.mlp.c_fc.weight
28.ca_layer.mlp.c_fc.bias
28.ca_layer.mlp.c_proj.weight
28.ca_layer.mlp.c_proj.bias
35.ca_layer.alpha_1
35.ca_layer.alpha_2
35.ca_layer.audio_expert.attn.W_q.weight
35.ca_layer.audio_expert.attn.W_kv.weight
35.ca_layer.audio_expert.attn.W_o.weight
35.ca_layer.audio_expert.attn.gate_linear.weight
35.ca_layer.visual_expert.attn.W_q.weight
35.ca_layer.visual_expert.attn.W_kv.weight
35.ca_layer.visual_expert.attn.W_o.weight
35.ca_layer.visual_expert.attn.gate_linear.weight
35.ca_layer.av_expert.attn.W_q.weight
35.ca_layer.av_expert.attn.W_kv.weight
35.ca_layer.av_expert.attn.W_o.weight
35.ca_layer.av_expert.attn.gate_linear.weight
35.ca_layer.ln_1.weight
35.ca_layer.ln_1.bias
35.ca_layer.ln_2.weight
35.ca_layer.ln_2.bias
35.ca_layer.mlp.c_fc.weight
35.ca_layer.mlp.c_fc.bias
35.ca_layer.mlp.c_proj.weight
35.ca_layer.mlp.c_proj.bias
0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.W_task.0.weight
Model.W_task.0.bias
Model.W_task.1.weight
Model.W_task.1.bias
Model.W_task.3.weight
Model.W_task.3.bias
Model.W_bn.weight
Model.W_bn.bias
Model.W_text.weight
Model.W_text.bias
Model.W_av.weight
Model.W_av.bias
Model.av_encoder.proj_a.weight
Model.av_encoder.proj_v.weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.0.linear1.weight
Model.av_encoder.enc_a.layers.0.linear1.bias
Model.av_encoder.enc_a.layers.0.linear2.weight
Model.av_encoder.enc_a.layers.0.linear2.bias
Model.av_encoder.enc_a.layers.0.norm1.weight
Model.av_encoder.enc_a.layers.0.norm1.bias
Model.av_encoder.enc_a.layers.0.norm2.weight
Model.av_encoder.enc_a.layers.0.norm2.bias
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.1.linear1.weight
Model.av_encoder.enc_a.layers.1.linear1.bias
Model.av_encoder.enc_a.layers.1.linear2.weight
Model.av_encoder.enc_a.layers.1.linear2.bias
Model.av_encoder.enc_a.layers.1.norm1.weight
Model.av_encoder.enc_a.layers.1.norm1.bias
Model.av_encoder.enc_a.layers.1.norm2.weight
Model.av_encoder.enc_a.layers.1.norm2.bias
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_a.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_a.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_a.layers.2.linear1.weight
Model.av_encoder.enc_a.layers.2.linear1.bias
Model.av_encoder.enc_a.layers.2.linear2.weight
Model.av_encoder.enc_a.layers.2.linear2.bias
Model.av_encoder.enc_a.layers.2.norm1.weight
Model.av_encoder.enc_a.layers.2.norm1.bias
Model.av_encoder.enc_a.layers.2.norm2.weight
Model.av_encoder.enc_a.layers.2.norm2.bias
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.0.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.0.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.0.linear1.weight
Model.av_encoder.enc_v.layers.0.linear1.bias
Model.av_encoder.enc_v.layers.0.linear2.weight
Model.av_encoder.enc_v.layers.0.linear2.bias
Model.av_encoder.enc_v.layers.0.norm1.weight
Model.av_encoder.enc_v.layers.0.norm1.bias
Model.av_encoder.enc_v.layers.0.norm2.weight
Model.av_encoder.enc_v.layers.0.norm2.bias
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.1.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.1.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.1.linear1.weight
Model.av_encoder.enc_v.layers.1.linear1.bias
Model.av_encoder.enc_v.layers.1.linear2.weight
Model.av_encoder.enc_v.layers.1.linear2.bias
Model.av_encoder.enc_v.layers.1.norm1.weight
Model.av_encoder.enc_v.layers.1.norm1.bias
Model.av_encoder.enc_v.layers.1.norm2.weight
Model.av_encoder.enc_v.layers.1.norm2.bias
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_weight
Model.av_encoder.enc_v.layers.2.self_attn.in_proj_bias
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.weight
Model.av_encoder.enc_v.layers.2.self_attn.out_proj.bias
Model.av_encoder.enc_v.layers.2.linear1.weight
Model.av_encoder.enc_v.layers.2.linear1.bias
Model.av_encoder.enc_v.layers.2.linear2.weight
Model.av_encoder.enc_v.layers.2.linear2.bias
Model.av_encoder.enc_v.layers.2.norm1.weight
Model.av_encoder.enc_v.layers.2.norm1.bias
Model.av_encoder.enc_v.layers.2.norm2.weight
Model.av_encoder.enc_v.layers.2.norm2.bias
Model.av_encoder.fusion.weight
Model.av_encoder.fusion.bias
Model.av_encoder.clf.weight
Model.av_encoder.clf.bias
Model.LN.weight
Model.LN.bias
The total number of trainable parameters is 140.73 M
Model.lang_encoder.transformer.wte.0.embedding.weight
Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Using grad with decay in Model.lang_encoder.transformer.wte.0.bn_embedding.bn_embedding
Model.lang_encoder.transformer.wpe.0.positional.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.0.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.0.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.1.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.1.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.2.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.2.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.3.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.3.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.4.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.4.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.5.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.5.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.6.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.6.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_1
Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.alpha_2
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.7.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.7.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.7.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.7.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.8.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.8.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.9.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.9.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.10.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.10.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.11.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.11.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.12.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.12.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.13.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.13.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_1
Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.alpha_2
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.14.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.14.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.14.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.14.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.15.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.15.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.16.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.16.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.17.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.17.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.18.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.18.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.19.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.19.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.20.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.20.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_1
Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.alpha_2
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.21.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.21.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.21.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.21.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.22.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.22.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.23.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.23.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.24.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.24.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.25.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.25.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.26.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.26.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.27.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.27.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_1
Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.alpha_2
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.28.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.28.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.28.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.28.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.29.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.29.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.30.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.30.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.31.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.31.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.32.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.32.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.33.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.33.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.34.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.34.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_1
Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.alpha_2
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.audio_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.visual_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_q.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_kv.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.W_o.weight
Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.av_expert.attn.gate_linear.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.weight
Model.lang_encoder.transformer.h.35.ca_layer.router.router_weights.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Using grad with decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Using grad with no decay in Model.lang_encoder.transformer.h.35.ca_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_1.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_attn.bias
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.attn.c_proj.bias
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.weight
Model.lang_encoder.transformer.h.35.decoder_layer.ln_2.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_fc.bias
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.weight
Model.lang_encoder.transformer.h.35.decoder_layer.mlp.c_proj.bias
Model.lang_encoder.transformer.ln_f.weight
Model.lang_encoder.transformer.ln_f.bias
Model.W_task.0.weight
Using grad with decay in Model.W_task.0.weight
Model.W_task.0.bias
Using grad with no decay in Model.W_task.0.bias
Model.W_task.1.weight
Using grad with decay in Model.W_task.1.weight
Model.W_task.1.bias
Using grad with no decay in Model.W_task.1.bias
Model.W_task.3.weight
Using grad with decay in Model.W_task.3.weight
Model.W_task.3.bias
Using grad with no decay in Model.W_task.3.bias
Model.W_bn.weight
Using grad with decay in Model.W_bn.weight
Model.W_bn.bias
Using grad with no decay in Model.W_bn.bias
Model.W_text.weight
Using grad with decay in Model.W_text.weight
Model.W_text.bias
Using grad with no decay in Model.W_text.bias
Model.W_av.weight
Using grad with decay in Model.W_av.weight
Model.W_av.bias
Using grad with no decay in Model.W_av.bias
Model.LN.weight
Using grad with decay in Model.LN.weight
Model.LN.bias
Using grad with no decay in Model.LN.bias
Will be using warmup for 63 steps
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0026], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0049], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0048], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0016], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0035], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0015], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0023], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0005], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0020], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0016], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0080], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0143], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0124], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0034], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0077], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0050], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0033], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0018], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0024], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0097], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0079], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0232], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0135], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0028], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0087], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0087], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0041], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0048], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0025], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0174], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0100], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0292], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0161], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0018], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0098], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0140], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0048], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0095], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0031], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0256], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0146], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0318], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0183], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0099], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0111], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0206], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0054], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0157], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0042], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0346], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0182], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0306], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0206], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0186], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0118], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0274], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0065], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0221], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0056], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0434], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0227], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0288], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0244], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0276], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0140], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0343], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0074], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0283], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0072], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0520], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0269], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0266], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0262], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0355], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0151], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0416], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0086], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0352], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0087], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0601], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0306], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0251], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0289], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0424], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0169], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0481], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0100], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0414], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0102], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0679], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0343], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0216], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0318], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0488], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0187], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0537], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0115], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0473], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0121], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0750], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0375], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0194], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0344], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0540], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0198], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0582], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0133], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0520], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0133], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0809], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0405], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0166], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0364], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0589], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0219], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0626], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0150], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0566], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0148], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0864], device='cuda:0', requires_grad=True)
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0431], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0145], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0383], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0631], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0230], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0665], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0164], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0605], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0160], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0911], device='cuda:0', requires_grad=True)
***************** Loading Model from checkpoints/thesis-mosei/msalm-mosei-1994.pth
Model alphas are
7.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0079], device='cuda:0', requires_grad=True)
7.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0232], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0135], device='cuda:0', requires_grad=True)
14.ca_layer.alpha_2 is: Parameter containing:
tensor([-0.0028], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0087], device='cuda:0', requires_grad=True)
21.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0087], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0041], device='cuda:0', requires_grad=True)
28.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0048], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_1 is: Parameter containing:
tensor([0.0025], device='cuda:0', requires_grad=True)
35.ca_layer.alpha_2 is: Parameter containing:
tensor([0.0174], device='cuda:0', requires_grad=True)
Deleting stored model from checkpoints/thesis-mosei/msalm-mosei-1994.pth
