2026-01-18 09:32:24,352 - MMSA [INFO] - ======================================== Program Start ========================================
2026-01-18 09:32:24,430 - MMSA [INFO] - Running with args:
2026-01-18 09:32:24,430 - MMSA [INFO] - {'model_name': 'msalm', 'dataset_name': 'sims', 'featurePath': '/leonardo_work/EUHPC_A04_051/alexfil/MSA-Datasets/CH-SIMS/unaligned_39.pkl', 'seq_lens': [39, 400, 55], 'feature_dims': [768, 33, 709], 'train_samples': 1368, 'num_classes': 3, 'language': 'cn', 'KeyEval': 'Loss', 'missing_rate': [0.0, 0.0, 0.0], 'missing_seed': [1111, 1111, 1111], 'need_data_aligned': False, 'need_model_aligned': False, 'early_stop': 10, 'use_bert': False, 'use_bert_finetune': False, 'attn_mask': True, 'excludeZero': True, 'update_epochs': 8, 'use_augmentation': False, 'use_m3xup': False, 'hfPath': False, 'use_ulgm': False, 'update_labels_patience': 1, 'H': 3.0, 'del_model': True, 'max_token_len': 39, 'pad_token': '<|endoftext|>', 'lm': '/leonardo_work/EUHPC_A04_051/alexfil/gpt2-chinese-cluecorpussmall', 'use_bf16': False, 'task_out': 1, 'use_clm': True, 'gamma': 1.0, 'l_bn': 1.0, 'l_av': 1.0, 'l_t': 1.0, 'warmup_epochs': 1, 'max_epochs': 100, 'beta_1': 0.9, 'beta_2': 0.95, 'use_lnorm': True, 'rescale': False, 'rescaler': 'sqrt', 'use_seqaug': True, 'n_bn_fusion': 16, 'modded_loss': True, 'embedding_attr_name': 'transformer.wte', 'decoder_layers_attr_name': 'transformer.h', 'mmgpt': {'type': 'gpt2', 'd_out': 64, 'combine': True, 'dropout': 0.1, 'mm_layer': [5, 6, 7, 8, 9, 10, 11], 'top_k': 2, 'layer_dropout': 0.0, 'dense': True, 'tie_ffn': True, 'n_embd': 768, 'bias': True, 'kv_dim': 30, 'n_head': 16, 'd_mm': 768, 'gating': 'sigmoid', 'init_gate': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'use_softperm': True, 'p_perm': 0.3, 'p_apply': 0.25, 'use_lora': False, 'lora': {'lora_alpha': 128, 'r': 64, 'lora_dropout': 0.05}}, 'av_enc': {'finetune': True, 'from_pretrained': True, 'path_to_pretrained': '/leonardo_work/EUHPC_A04_051/alexfil/DeepMLF-Reprod/checkpoints/bienc-sims-1990/bienc-sims-1990.pth', 'feature_dims': [768, 33, 709], 'd_enc': 30, 'n_embd': 30, 'n_head': 6, 'nlevels': 3, 'd_enc_out': 30, 'maxlen': 55, 'p_mask': 0.15, 'enc_attn_dropout': 0.1, 'enc_res_dropout': 0.1, 'enc_dropout': 0.1, 'use_softperm': True, 'p_perm': 0.2, 'mask_perm_ratio': 0.5, 'tf_fusion': False, 'use_bn': True, 'use_ln': False}, 'gpt': {'vocab_size': 50257, 'block_size': 1024, 'bias': True, 'n_embd': 1024, 'n_layer': 24, 'n_head': 16, 'dropout': 0.0}, 'batch_size': 32, 'grad_clip': 5.0, 'patience': 10, 'weight_decay_mmgpt': 0.1, 'weight_decay_av': 0.1, 'learning_rate_av': 0.0001, 'learning_rate_mmgpt': 0.0001, 'device': device(type='cuda', index=0), 'train_mode': 'regression', 'custom_feature': None, 'feature_T': '', 'feature_A': '', 'feature_V': ''}
2026-01-18 09:32:24,430 - MMSA [INFO] - Seeds: [1990]
2026-01-18 09:32:24,431 - MMSA [INFO] - ------------------------------ Running with seed 1990 [1/1] ------------------------------
2026-01-18 09:33:49,634 - MMSA [INFO] - The model has 173499052 trainable parameters
2026-01-18 09:34:00,095 - MMSA [INFO] - TRAIN-(msalm) [1/1/1] >> loss: 0.6211  Mult_acc_2: 0.6440  Mult_acc_3: 0.4678  Mult_acc_5: 0.2091  F1_score: 0.5975  MAE: 0.6188  Corr: 0.0595  clm loss: 7.7703 total loss: 10.892 bn loss: 0.8901 av loss: 0.6673 text loss: 0.9433
2026-01-18 09:34:02,159 - MMSA [INFO] - VAL-(msalm) >>  Mult_acc_2: 0.6425  Mult_acc_3: 0.4496  Mult_acc_5: 0.1864  F1_score: 0.6273  MAE: 0.5985  Corr: 0.1504  Loss: 0.5989 
2026-01-18 09:34:11,884 - MMSA [INFO] - TRAIN-(msalm) [1/2/1] >> loss: 0.5832  Mult_acc_2: 0.6776  Mult_acc_3: 0.5080  Mult_acc_5: 0.2383  F1_score: 0.6367  MAE: 0.5820  Corr: 0.1939  clm loss: 6.907 total loss: 9.7022 bn loss: 0.7361 av loss: 0.6323 text loss: 0.8436
2026-01-18 09:34:13,776 - MMSA [INFO] - VAL-(msalm) >>  Mult_acc_2: 0.6908  Mult_acc_3: 0.5088  Mult_acc_5: 0.1930  F1_score: 0.6745  MAE: 0.5517  Corr: 0.3497  Loss: 0.5575 
2026-01-18 09:34:23,383 - MMSA [INFO] - TRAIN-(msalm) [1/3/1] >> loss: 0.5541  Mult_acc_2: 0.7003  Mult_acc_3: 0.5395  Mult_acc_5: 0.2537  F1_score: 0.6757  MAE: 0.5506  Corr: 0.3337  clm loss: 6.1231 total loss: 8.655 bn loss: 0.6354 av loss: 0.6055 text loss: 0.7369
2026-01-18 09:34:25,276 - MMSA [INFO] - VAL-(msalm) >>  Mult_acc_2: 0.7215  Mult_acc_3: 0.5570  Mult_acc_5: 0.2654  F1_score: 0.7122  MAE: 0.5227  Corr: 0.4372  Loss: 0.5275 
2026-01-18 09:34:34,916 - MMSA [INFO] - TRAIN-(msalm) [1/4/1] >> loss: 0.5235  Mult_acc_2: 0.7325  Mult_acc_3: 0.5841  Mult_acc_5: 0.2829  F1_score: 0.7237  MAE: 0.5136  Corr: 0.4423  clm loss: 5.4555 total loss: 7.8324 bn loss: 0.581 av loss: 0.582 text loss: 0.6905
2026-01-18 09:34:36,763 - MMSA [INFO] - VAL-(msalm) >>  Mult_acc_2: 0.6798  Mult_acc_3: 0.5680  Mult_acc_5: 0.2917  F1_score: 0.6900  MAE: 0.5134  Corr: 0.4705  Loss: 0.5244 
2026-01-18 09:34:46,358 - MMSA [INFO] - TRAIN-(msalm) [1/5/1] >> loss: 0.4974  Mult_acc_2: 0.7580  Mult_acc_3: 0.6213  Mult_acc_5: 0.3355  F1_score: 0.7563  MAE: 0.4769  Corr: 0.5162  clm loss: 4.9051 total loss: 7.1545 bn loss: 0.559 av loss: 0.5679 text loss: 0.6249
2026-01-18 09:34:48,164 - MMSA [INFO] - VAL-(msalm) >>  Mult_acc_2: 0.6732  Mult_acc_3: 0.5614  Mult_acc_5: 0.2851  F1_score: 0.6843  MAE: 0.5234  Corr: 0.4689  Loss: 0.5376 
2026-01-18 09:34:56,843 - MMSA [INFO] - TRAIN-(msalm) [2/6/1] >> loss: 0.4942  Mult_acc_2: 0.7588  Mult_acc_3: 0.6345  Mult_acc_5: 0.3487  F1_score: 0.7573  MAE: 0.4659  Corr: 0.5421  clm loss: 4.4611 total loss: 6.6477 bn loss: 0.5417 av loss: 0.5517 text loss: 0.5989
2026-01-18 09:34:58,717 - MMSA [INFO] - VAL-(msalm) >>  Mult_acc_2: 0.6732  Mult_acc_3: 0.5680  Mult_acc_5: 0.3026  F1_score: 0.6853  MAE: 0.5291  Corr: 0.4698  Loss: 0.5506 
2026-01-18 09:35:07,251 - MMSA [INFO] - TRAIN-(msalm) [3/7/1] >> loss: 0.4739  Mult_acc_2: 0.7690  Mult_acc_3: 0.6404  Mult_acc_5: 0.3596  F1_score: 0.7663  MAE: 0.4593  Corr: 0.5581  clm loss: 4.1879 total loss: 6.338 bn loss: 0.5321 av loss: 0.5381 text loss: 0.606
2026-01-18 09:35:09,104 - MMSA [INFO] - VAL-(msalm) >>  Mult_acc_2: 0.7039  Mult_acc_3: 0.5877  Mult_acc_5: 0.3268  F1_score: 0.7125  MAE: 0.4975  Corr: 0.5034  Loss: 0.5078 
2026-01-18 09:35:18,631 - MMSA [INFO] - TRAIN-(msalm) [1/8/1] >> loss: 0.4835  Mult_acc_2: 0.7471  Mult_acc_3: 0.6104  Mult_acc_5: 0.3304  F1_score: 0.7443  MAE: 0.4711  Corr: 0.5332  clm loss: 3.9603 total loss: 6.086 bn loss: 0.5246 av loss: 0.526 text loss: 0.5916
2026-01-18 09:35:20,562 - MMSA [INFO] - VAL-(msalm) >>  Mult_acc_2: 0.7215  Mult_acc_3: 0.6096  Mult_acc_5: 0.3662  F1_score: 0.7273  MAE: 0.4753  Corr: 0.5321  Loss: 0.4851 
2026-01-18 09:35:30,124 - MMSA [INFO] - TRAIN-(msalm) [1/9/1] >> loss: 0.4673  Mult_acc_2: 0.7610  Mult_acc_3: 0.6301  Mult_acc_5: 0.3392  F1_score: 0.7594  MAE: 0.4561  Corr: 0.5683  clm loss: 3.7486 total loss: 5.8315 bn loss: 0.5181 av loss: 0.5151 text loss: 0.5824
2026-01-18 09:35:31,944 - MMSA [INFO] - VAL-(msalm) >>  Mult_acc_2: 0.7434  Mult_acc_3: 0.6184  Mult_acc_5: 0.3794  F1_score: 0.7437  MAE: 0.4688  Corr: 0.5391  Loss: 0.4964 
